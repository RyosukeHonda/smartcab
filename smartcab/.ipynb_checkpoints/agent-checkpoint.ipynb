{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('red', None, 'left', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'right', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', None, 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'left', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'right', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'left', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'right', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'right', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'left', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'right', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', None, 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'forward', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'right', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'left', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'left', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', None, 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'right', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'left', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', None, 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, None, 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'right', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'forward', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'forward', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'right', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'left', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'forward', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'forward', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'forward', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'forward', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'right', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'forward', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'left', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'left', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'right', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'right', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'right', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'forward', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'left', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'forward', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'forward', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'right', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'forward', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', None, None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'left', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', None, 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'forward', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, None, None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', None, 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'left', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'forward', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'right', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'right', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', None, 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', None, 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', None, 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'left', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'right', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'right', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'right', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'right', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'right', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'right', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'right', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'forward', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', None, 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', None, 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'forward', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', None, None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'left', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', None, 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', None, 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'left', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'right', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', None, None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'forward', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'forward', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'forward', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', None, 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'right', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'right', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'forward', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', None, 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'forward', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, None, 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'forward', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'left', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'forward', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'right', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'forward', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'left', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'left', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', None, 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'left', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'forward', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', None, None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'right', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', None, 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'left', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'left', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'left', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'left', 'left', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'left', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'forward', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', None, None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'right', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'right', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, 'forward', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'left', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, None, None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, 'forward', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, None, 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'forward', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, None, 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'right', None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'left', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', None, 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'left', 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'left', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', None, None): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'forward', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'right', 'left', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'forward', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', None, None, 'forward'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', None, None, 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'forward', 'left', 'right'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('green', 'right', 'left', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'left', 'right', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}, ('red', 'forward', 'forward', 'left'): {'forward': 0, 'right': 0, None: 0, 'left': 0}}\n",
      "Simulator.__init__(): Error initializing GUI objects; display disabled.\n",
      "error: Couldn't open images/car-orange.png\n",
      "Simulator.run(): Trial 0\n",
      "Environment.reset(): Trial set up with start = (1, 1), destination = (7, 1), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (7, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': -0.5}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 1\n",
      "Environment.reset(): Trial set up with start = (8, 3), destination = (1, 4), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (1, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.3333333333333333, 'right': 0, None: 0, 'left': -0.5}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:2\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', 'left', None)\n",
      "t:2\n",
      "0.333333333333 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:3\n",
      "{'forward': -0.3333333333333333, 'right': 0, None: 0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', 'left', None)\n",
      "t:3\n",
      "0.25 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': 'left', 'right': 'right', 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', 'left', None)\n",
      "t:4\n",
      "0.2 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', 'left', None)\n",
      "t:5\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -0.5\n",
      "Total Reward -2.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "{'forward': -0.5, 'right': 0, None: 0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -0.5\n",
      "Total Reward -3.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:7\n",
      "{'forward': -0.5, 'right': 0, None: 0, 'left': -0.07142857142857142}\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "{'forward': 0, 'right': 0, None: 0.0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -0.6666666666666666, 'right': 0, None: 0, 'left': -0.5}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.6666666666666666, 'right': 0, None: 0, 'left': -0.5357142857142857}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -0.6888888888888889, 'right': 0, None: 0, 'left': -0.5357142857142857}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:19\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:20\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 21.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:20\n",
      "0.047619047619 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 2\n",
      "Environment.reset(): Trial set up with start = (5, 3), destination = (2, 2), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': 0, None: 0, 'left': 0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': -0.25}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "{'forward': 0, 'right': 0, None: 0.0, 'left': -0.1}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "{'forward': -0.125, 'right': 0, None: 0.0, 'left': -0.1}\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 15.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 3\n",
      "Environment.reset(): Trial set up with start = (7, 3), destination = (4, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:2\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.6888888888888889, 'right': 0, None: 0, 'left': -0.5615079365079365}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': -0.25}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': -0.25}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': -0.35714285714285715}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -0.6888888888888889, 'right': -0.1, None: 0, 'left': -0.5615079365079365}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -0.6888888888888889, 'right': -0.1, None: 0, 'left': -0.6053571428571428}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -0.6888888888888889, 'right': -0.1, None: 0, 'left': -0.6412337662337662}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.7148148148148148, 'right': -0.1, None: 0, 'left': -0.6668599257884972}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:15\n",
      "0.0625 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 4\n",
      "Environment.reset(): Trial set up with start = (2, 3), destination = (8, 2), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (8, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.7148148148148148, 'right': -0.1, None: 0, 'left': -0.689069264069264}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.8098765432098766, 'right': -0.1, None: 0, 'left': -0.689069264069264}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.8574074074074074, 'right': -0.1, None: 0, 'left': -0.689069264069264}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': -0.35714285714285715}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': -0.35714285714285715}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:11\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -0.8574074074074074, 'right': -0.1, None: 0, 'left': -0.7512554112554113}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:13\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.8574074074074074, 'right': -0.12862508582006726, None: 0, 'left': -0.7512554112554113}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "{'forward': -0.8669135802469136, 'right': -0.12862508582006726, None: 0, 'left': -0.7512554112554113}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': -0.35714285714285715}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': 0, None: 0.0, 'left': -0.35714285714285715}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = right, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:22\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:23\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:24\n",
      "{'forward': -0.8752314814814814, 'right': -0.12862508582006726, None: 0, 'left': -0.7512554112554113}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:24\n",
      "0.04 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:25\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 12.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 26\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:26\n",
      "{'forward': -0.8800302706552706, 'right': -0.12862508582006726, None: 0, 'left': -0.7612051948051949}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 12.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "0.037037037037 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 27\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:27\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "0.0357142857143 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 28\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "{'forward': -0.8800302706552706, 'right': -0.13153764996721742, None: 0, 'left': -0.7612051948051949}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "0.0344827586207 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 29\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "{'forward': -0.8800302706552706, 'right': -0.13153764996721742, None: 0, 'left': -0.769439498432602}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "0.0333333333333 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 30\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:30\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:30\n",
      "0.0322580645161 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 31\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:31\n",
      "{'forward': -0.8800302706552706, 'right': -0.13153764996721742, None: 0.0, 'left': -0.769439498432602}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:31\n",
      "0.03125 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 31\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 32\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:32\n",
      "{'forward': -0.8800302706552706, 'right': -0.13153764996721742, None: 0.0, 'left': -0.7766445141065832}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:32\n",
      "0.030303030303 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 33\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:33\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:33\n",
      "0.0294117647059 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 33\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 34\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:34\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:34\n",
      "0.0285714285714 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 34\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 35\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:35\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:35\n",
      "0.0277777777778 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 35\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 5\n",
      "Environment.reset(): Trial set up with start = (6, 6), destination = (8, 2), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (8, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.019054216212555253, None: 0.0, 'left': -0.35714285714285715}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.019054216212555253, None: 0.0, 'left': -0.5178571428571428}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -0.8836657169990503, 'right': -0.13153764996721742, None: 0.0, 'left': -0.7766445141065832}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.8836657169990503, 'right': -0.18417512854332924, None: 0.0, 'left': -0.7766445141065832}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -0.8836657169990503, 'right': -0.21833671326113718, None: 0.0, 'left': -0.7766445141065832}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -0.8836657169990503, 'right': -0.21833671326113718, None: 0.0, 'left': -0.795257471264368}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.8919753086419753, 'right': -0.21833671326113718, None: 0.0, 'left': -0.795257471264368}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "{'forward': -0.8919753086419753, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8089069731800768}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -0.8983297022512708, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8089069731800768}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "{'forward': -0.8983297022512708, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8195232524478503}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "{'forward': -0.9036807705538357, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8285470898254578}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "{'forward': -0.9080589173468432, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8285470898254578}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "{'forward': -0.9120563557230674, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8285470898254578}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:24\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:24\n",
      "0.04 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:25\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 26\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "0.037037037037 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 27\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "0.0357142857143 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 28\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "{'forward': -0.9157206742346062, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8285470898254578}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "0.0344827586207 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 29\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "{'forward': -0.9157206742346062, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8285470898254578}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "0.0333333333333 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 30\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:30\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 25.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:30\n",
      "0.0322580645161 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 6\n",
      "Environment.reset(): Trial set up with start = (5, 3), destination = (2, 2), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.9157206742346062, 'right': -0.21833671326113718, None: 0.0, 'left': -0.8285470898254578}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 15.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 7\n",
      "Environment.reset(): Trial set up with start = (2, 6), destination = (4, 1), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (4, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -0.9157206742346062, 'right': -0.3294031071127223, None: 0.0, 'left': -0.8285470898254578}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -0.9297672285288385, 'right': -0.3294031071127223, None: 0.0, 'left': -0.8285470898254578}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.9297672285288385, 'right': -0.3294031071127223, None: 0.0, 'left': -0.8285470898254578}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:13\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.9297672285288385, 'right': -0.34019448643014316, None: 0.0, 'left': -0.8499787035972756}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 20.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 20.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -0.9297672285288385, 'right': -0.3445947447463983, None: 0.0, 'left': -0.8499787035972756}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "{'forward': -0.9297672285288385, 'right': -0.3445947447463983, None: 0.0, 'left': -0.8574797684174118}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:22\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 30.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 8\n",
      "Environment.reset(): Trial set up with start = (6, 1), destination = (2, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (2, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.9297672285288385, 'right': -0.3445947447463983, None: 0.0, 'left': -0.8642664461118208}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.9531781523525591, 'right': -0.3445947447463983, None: 0.0, 'left': -0.8642664461118208}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.019054216212555253, None: 0.0, 'left': -0.5178571428571428}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.019054216212555253, None: 0.0, 'left': -0.5867346938775511}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -0.9531781523525591, 'right': -0.3445947447463983, None: 0.0, 'left': -0.8642664461118208}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -0.9531781523525591, 'right': -0.3445947447463983, None: 0.0, 'left': -0.8778398015006387}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -0.9531781523525591, 'right': -0.34479087972915357, None: 0.0, 'left': -0.8778398015006387}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 27.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 9\n",
      "Environment.reset(): Trial set up with start = (4, 6), destination = (6, 2), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "137    13    14.5        22        8\n",
      "138    14    14.0        21        8\n",
      "139    15    16.0        20        8\n",
      "140    16    18.0        19        8\n",
      "141    17    20.0        18        8\n",
      "142    18    20.0        17        8\n",
      "143    19    19.0        16        8\n",
      "144    20    18.0        15        8\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "\n",
      "[167 rows x 4 columns]\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "138    14    14.0        21        8\n",
      "139    15    16.0        20        8\n",
      "140    16    18.0        19        8\n",
      "141    17    20.0        18        8\n",
      "142    18    20.0        17        8\n",
      "143    19    19.0        16        8\n",
      "144    20    18.0        15        8\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "\n",
      "[168 rows x 4 columns]\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "139    15    16.0        20        8\n",
      "140    16    18.0        19        8\n",
      "141    17    20.0        18        8\n",
      "142    18    20.0        17        8\n",
      "143    19    19.0        16        8\n",
      "144    20    18.0        15        8\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "\n",
      "[169 rows x 4 columns]\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.07249263663338244, None: 0.0, 'left': -0.5867346938775511}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "140    16    18.0        19        8\n",
      "141    17    20.0        18        8\n",
      "142    18    20.0        17        8\n",
      "143    19    19.0        16        8\n",
      "144    20    18.0        15        8\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "\n",
      "[170 rows x 4 columns]\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "141    17    20.0        18        8\n",
      "142    18    20.0        17        8\n",
      "143    19    19.0        16        8\n",
      "144    20    18.0        15        8\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "\n",
      "[171 rows x 4 columns]\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "142    18    20.0        17        8\n",
      "143    19    19.0        16        8\n",
      "144    20    18.0        15        8\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "\n",
      "[172 rows x 4 columns]\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "143    19    19.0        16        8\n",
      "144    20    18.0        15        8\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "\n",
      "[173 rows x 4 columns]\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:7\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "144    20    18.0        15        8\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "\n",
      "[174 rows x 4 columns]\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.07249263663338244, None: 0.0, 'left': -0.6900510204081634}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "145    21    18.0        14        8\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "\n",
      "[175 rows x 4 columns]\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('red', 'right', 'right', None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "146    22    30.0        13        8\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "\n",
      "[176 rows x 4 columns]\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "147     0     2.0        25        9\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "\n",
      "[177 rows x 4 columns]\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "148     1     4.0        24        9\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "\n",
      "[178 rows x 4 columns]\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "149     2     3.0        23        9\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "\n",
      "[179 rows x 4 columns]\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:13\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 15.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "150     3     3.0        22        9\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "\n",
      "[180 rows x 4 columns]\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "151     4     5.0        21        9\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "\n",
      "[181 rows x 4 columns]\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10], [15, 19.5, 15, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "152     5     7.0        20        9\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "181    15    19.5        15       10\n",
      "\n",
      "[182 rows x 4 columns]\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 21.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10], [15, 19.5, 15, 10], [16, 21.5, 14, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "153     6     6.0        19        9\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "181    15    19.5        15       10\n",
      "182    16    21.5        14       10\n",
      "\n",
      "[183 rows x 4 columns]\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 23.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10], [15, 19.5, 15, 10], [16, 21.5, 14, 10], [17, 23.5, 13, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "154     7     5.0        18        9\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "181    15    19.5        15       10\n",
      "182    16    21.5        14       10\n",
      "183    17    23.5        13       10\n",
      "\n",
      "[184 rows x 4 columns]\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "{'forward': -0.9531781523525591, 'right': -0.34479087972915357, None: 0.0, 'left': -0.8778398015006387}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 22.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10], [15, 19.5, 15, 10], [16, 21.5, 14, 10], [17, 23.5, 13, 10], [18, 22.5, 12, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "155     8     4.5        17        9\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "181    15    19.5        15       10\n",
      "182    16    21.5        14       10\n",
      "183    17    23.5        13       10\n",
      "184    18    22.5        12       10\n",
      "\n",
      "[185 rows x 4 columns]\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -0.9556424601234772, 'right': -0.34479087972915357, None: 0.0, 'left': -0.8778398015006387}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 22.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10], [15, 19.5, 15, 10], [16, 21.5, 14, 10], [17, 23.5, 13, 10], [18, 22.5, 12, 10], [19, 22.5, 11, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "156     9     3.5        16        9\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "181    15    19.5        15       10\n",
      "182    16    21.5        14       10\n",
      "183    17    23.5        13       10\n",
      "184    18    22.5        12       10\n",
      "185    19    22.5        11       10\n",
      "\n",
      "[186 rows x 4 columns]\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 22.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10], [15, 19.5, 15, 10], [16, 21.5, 14, 10], [17, 23.5, 13, 10], [18, 22.5, 12, 10], [19, 22.5, 11, 10], [20, 22.5, 10, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "157    10     5.5        15        9\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "181    15    19.5        15       10\n",
      "182    16    21.5        14       10\n",
      "183    17    23.5        13       10\n",
      "184    18    22.5        12       10\n",
      "185    19    22.5        11       10\n",
      "186    20    22.5        10       10\n",
      "\n",
      "[187 rows x 4 columns]\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 24.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10], [15, 19.5, 15, 10], [16, 21.5, 14, 10], [17, 23.5, 13, 10], [18, 22.5, 12, 10], [19, 22.5, 11, 10], [20, 22.5, 10, 10], [21, 24.5, 9, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "158    11     7.5        14        9\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "181    15    19.5        15       10\n",
      "182    16    21.5        14       10\n",
      "183    17    23.5        13       10\n",
      "184    18    22.5        12       10\n",
      "185    19    22.5        11       10\n",
      "186    20    22.5        10       10\n",
      "187    21    24.5         9       10\n",
      "\n",
      "[188 rows x 4 columns]\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:22\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 36.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:22\n",
      "0.0434782608696 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[0, -0.5, 30, 1], [1, -1.5, 29, 1], [2, -2.5, 28, 1], [3, 9.5, 27, 1], [0, 2.0, 40, 2], [1, 1.0, 39, 2], [2, 0.0, 38, 2], [3, -1.0, 37, 2], [4, -2.0, 36, 2], [5, -2.5, 35, 2], [6, -3.0, 34, 2], [7, -1.0, 33, 2], [8, -1.0, 32, 2], [9, -2.0, 31, 2], [10, 0.0, 30, 2], [11, 2.0, 29, 2], [12, 4.0, 28, 2], [13, 3.0, 27, 2], [14, 2.0, 26, 2], [15, 4.0, 25, 2], [16, 6.0, 24, 2], [17, 5.0, 23, 2], [18, 7.0, 22, 2], [19, 9.0, 21, 2], [20, 21.0, 20, 2], [0, -1.0, 20, 3], [1, -2.0, 19, 3], [2, -2.0, 18, 3], [3, -3.0, 17, 3], [4, -3.0, 16, 3], [5, -1.0, 15, 3], [6, -1.5, 14, 3], [7, -2.5, 13, 3], [8, -0.5, 12, 3], [9, 1.5, 11, 3], [10, 3.5, 10, 3], [11, 15.5, 9, 3], [0, 2.0, 20, 4], [1, 1.5, 19, 4], [2, 3.5, 18, 4], [3, 5.5, 17, 4], [4, 5.0, 16, 4], [5, 4.0, 15, 4], [6, 3.0, 14, 4], [7, 3.0, 13, 4], [8, 5.0, 12, 4], [9, 4.0, 11, 4], [10, 3.0, 10, 4], [11, 2.0, 9, 4], [12, 4.0, 8, 4], [13, 3.0, 7, 4], [14, 2.0, 6, 4], [15, 14.0, 5, 4], [0, 2.0, 35, 5], [1, 4.0, 34, 5], [2, 3.0, 33, 5], [3, 2.0, 32, 5], [4, 1.0, 31, 5], [5, 3.0, 30, 5], [6, 5.0, 29, 5], [7, 4.5, 28, 5], [8, 3.5, 27, 5], [9, 3.5, 26, 5], [10, 3.5, 25, 5], [11, 5.5, 24, 5], [12, 5.0, 23, 5], [13, 7.0, 22, 5], [14, 6.0, 21, 5], [15, 5.0, 20, 5], [16, 7.0, 19, 5], [17, 7.0, 18, 5], [18, 7.0, 17, 5], [19, 6.5, 16, 5], [20, 8.5, 15, 5], [21, 10.5, 14, 5], [22, 12.5, 13, 5], [23, 14.5, 12, 5], [24, 13.5, 11, 5], [25, 12.5, 10, 5], [26, 12.0, 9, 5], [27, 14.0, 8, 5], [28, 13.0, 7, 5], [29, 13.0, 6, 5], [30, 15.0, 5, 5], [31, 14.0, 4, 5], [32, 13.0, 3, 5], [33, 15.0, 2, 5], [34, 17.0, 1, 5], [35, 19.0, 0, 5], [0, 2.0, 30, 6], [1, 4.0, 29, 6], [2, 6.0, 28, 6], [3, 5.0, 27, 6], [4, 4.0, 26, 6], [5, 6.0, 25, 6], [6, 5.5, 24, 6], [7, 5.0, 23, 6], [8, 7.0, 22, 6], [9, 9.0, 21, 6], [10, 11.0, 20, 6], [11, 10.0, 19, 6], [12, 12.0, 18, 6], [13, 11.0, 17, 6], [14, 10.0, 16, 6], [15, 12.0, 15, 6], [16, 11.0, 14, 6], [17, 10.0, 13, 6], [18, 9.0, 12, 6], [19, 8.0, 11, 6], [20, 10.0, 10, 6], [21, 9.0, 9, 6], [22, 8.0, 8, 6], [23, 7.0, 7, 6], [24, 9.0, 6, 6], [25, 11.0, 5, 6], [26, 13.0, 4, 6], [27, 13.0, 3, 6], [28, 13.0, 2, 6], [29, 13.0, 1, 6], [30, 25.0, 0, 6], [0, 2.0, 20, 7], [1, 1.5, 19, 7], [2, 3.5, 18, 7], [3, 15.5, 17, 7], [0, 2.0, 35, 8], [1, 4.0, 34, 8], [2, 6.0, 33, 8], [3, 8.0, 32, 8], [4, 10.0, 31, 8], [5, 9.0, 30, 8], [6, 9.0, 29, 8], [7, 8.0, 28, 8], [8, 7.5, 27, 8], [9, 6.5, 26, 8], [10, 8.5, 25, 8], [11, 10.5, 24, 8], [12, 12.5, 23, 8], [13, 14.5, 22, 8], [14, 14.0, 21, 8], [15, 16.0, 20, 8], [16, 18.0, 19, 8], [17, 20.0, 18, 8], [18, 20.0, 17, 8], [19, 19.0, 16, 8], [20, 18.0, 15, 8], [21, 18.0, 14, 8], [22, 30.0, 13, 8], [0, 2.0, 25, 9], [1, 4.0, 24, 9], [2, 3.0, 23, 9], [3, 3.0, 22, 9], [4, 5.0, 21, 9], [5, 7.0, 20, 9], [6, 6.0, 19, 9], [7, 5.0, 18, 9], [8, 4.5, 17, 9], [9, 3.5, 16, 9], [10, 5.5, 15, 9], [11, 7.5, 14, 9], [12, 7.0, 13, 9], [13, 9.0, 12, 9], [14, 11.0, 11, 9], [15, 13.0, 10, 9], [16, 15.0, 9, 9], [17, 15.0, 8, 9], [18, 27.0, 7, 9], [0, 2.0, 30, 10], [1, 4.0, 29, 10], [2, 6.0, 28, 10], [3, 5.0, 27, 10], [4, 4.5, 26, 10], [5, 6.5, 25, 10], [6, 8.5, 24, 10], [7, 10.5, 23, 10], [8, 10.0, 22, 10], [9, 12.0, 21, 10], [10, 14.0, 20, 10], [11, 14.0, 19, 10], [12, 16.0, 18, 10], [13, 15.5, 17, 10], [14, 17.5, 16, 10], [15, 19.5, 15, 10], [16, 21.5, 14, 10], [17, 23.5, 13, 10], [18, 22.5, 12, 10], [19, 22.5, 11, 10], [20, 22.5, 10, 10], [21, 24.5, 9, 10], [22, 36.5, 8, 10]]\n",
      "     Time  Reward  Deadline  Episode\n",
      "0       0    -0.5        30        1\n",
      "1       1    -1.5        29        1\n",
      "2       2    -2.5        28        1\n",
      "3       3     9.5        27        1\n",
      "4       0     2.0        40        2\n",
      "5       1     1.0        39        2\n",
      "6       2     0.0        38        2\n",
      "7       3    -1.0        37        2\n",
      "8       4    -2.0        36        2\n",
      "9       5    -2.5        35        2\n",
      "10      6    -3.0        34        2\n",
      "11      7    -1.0        33        2\n",
      "12      8    -1.0        32        2\n",
      "13      9    -2.0        31        2\n",
      "14     10     0.0        30        2\n",
      "15     11     2.0        29        2\n",
      "16     12     4.0        28        2\n",
      "17     13     3.0        27        2\n",
      "18     14     2.0        26        2\n",
      "19     15     4.0        25        2\n",
      "20     16     6.0        24        2\n",
      "21     17     5.0        23        2\n",
      "22     18     7.0        22        2\n",
      "23     19     9.0        21        2\n",
      "24     20    21.0        20        2\n",
      "25      0    -1.0        20        3\n",
      "26      1    -2.0        19        3\n",
      "27      2    -2.0        18        3\n",
      "28      3    -3.0        17        3\n",
      "29      4    -3.0        16        3\n",
      "..    ...     ...       ...      ...\n",
      "159    12     7.0        13        9\n",
      "160    13     9.0        12        9\n",
      "161    14    11.0        11        9\n",
      "162    15    13.0        10        9\n",
      "163    16    15.0         9        9\n",
      "164    17    15.0         8        9\n",
      "165    18    27.0         7        9\n",
      "166     0     2.0        30       10\n",
      "167     1     4.0        29       10\n",
      "168     2     6.0        28       10\n",
      "169     3     5.0        27       10\n",
      "170     4     4.5        26       10\n",
      "171     5     6.5        25       10\n",
      "172     6     8.5        24       10\n",
      "173     7    10.5        23       10\n",
      "174     8    10.0        22       10\n",
      "175     9    12.0        21       10\n",
      "176    10    14.0        20       10\n",
      "177    11    14.0        19       10\n",
      "178    12    16.0        18       10\n",
      "179    13    15.5        17       10\n",
      "180    14    17.5        16       10\n",
      "181    15    19.5        15       10\n",
      "182    16    21.5        14       10\n",
      "183    17    23.5        13       10\n",
      "184    18    22.5        12       10\n",
      "185    19    22.5        11       10\n",
      "186    20    22.5        10       10\n",
      "187    21    24.5         9       10\n",
      "188    22    36.5         8       10\n",
      "\n",
      "[189 rows x 4 columns]\n",
      "Simulator.run(): Trial 10\n",
      "Environment.reset(): Trial set up with start = (1, 6), destination = (5, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.9556424601234772, 'right': -0.34479087972915357, None: 0.0, 'left': -0.8778398015006387}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 19.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 11\n",
      "Environment.reset(): Trial set up with start = (4, 2), destination = (6, 6), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.10999894248382527, None: 0.0, 'left': -0.6900510204081634}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.10999894248382527, None: 0.0, 'left': -0.6900510204081634}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.10999894248382527, None: 0.0, 'left': -0.6900510204081634}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 16.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 12\n",
      "Environment.reset(): Trial set up with start = (8, 5), destination = (4, 2), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (4, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.10999894248382527, None: 0.0, 'left': -0.6900510204081634}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.9556424601234772, 'right': -0.43034242324837435, None: 0.0, 'left': -0.8778398015006387}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.9556424601234772, 'right': -0.43640854049210076, None: 0.0, 'left': -0.8778398015006387}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', 'right', None)\n",
      "t:5\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'left', 'right', None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': 'right', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.6900510204081634}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.6900510204081634}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 13\n",
      "Environment.reset(): Trial set up with start = (3, 1), destination = (7, 1), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.9556424601234772, 'right': -0.4491268323936807, None: 0.0, 'left': -0.8778398015006387}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.9778212300617386, 'right': -0.4491268323936807, None: 0.0, 'left': -0.8778398015006387}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -0.9815176917181155, 'right': -0.4491268323936807, None: 0.0, 'left': -0.908379851125479}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.7287946428571429}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'right', None, 'forward')\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'right', None, 'forward')\n",
      "t:8\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -0.9815176917181155, 'right': -0.456394427766012, None: 0.0, 'left': -0.908379851125479}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 14\n",
      "Environment.reset(): Trial set up with start = (3, 1), destination = (5, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (5, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:2\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.9830578840749392, 'right': -0.456394427766012, None: 0.0, 'left': -0.908379851125479}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, 'left')\n",
      "t:4\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -0.9830578840749392, 'right': -0.456394427766012, None: 0.0, 'left': -0.9312848883441093}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.9830578840749392, 'right': -0.456394427766012, None: 0.0, 'left': -0.9411013328663795}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -0.9830578840749392, 'right': -0.456394427766012, None: 0.0, 'left': -0.9484636662580821}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -0.9830578840749392, 'right': -0.456394427766012, None: 0.0, 'left': -0.9541899255627395}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 15\n",
      "Environment.reset(): Trial set up with start = (4, 2), destination = (7, 4), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (7, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:2\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -0.9830578840749392, 'right': -0.456394427766012, None: 0.0, 'left': -0.9541899255627395}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.9830578840749392, 'right': -0.456394427766012, None: 0.0, 'left': -0.9541899255627395}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -0.9851756485655718, 'right': -0.456394427766012, None: 0.0, 'left': -0.9541899255627395}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -0.9851756485655718, 'right': -0.456394427766012, None: 0.0, 'left': -0.9541899255627395}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 19.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 12.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 16\n",
      "Environment.reset(): Trial set up with start = (1, 3), destination = (8, 5), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (8, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0217391304348\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0222222222222\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0227272727273\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0232558139535\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.9866580837090146, 'right': -0.456394427766012, None: 0.0, 'left': -0.9541899255627395}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0238095238095\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.7287946428571429}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.7287946428571429}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.7287946428571429}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.7626953125}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.7626953125}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:10\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -0.9866580837090146, 'right': -0.4550447774426639, None: 0.0, 'left': -0.9541899255627395}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.9866580837090146, 'right': -0.4550447774426639, None: 0.0, 'left': -0.9541899255627395}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "0.0625 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:16\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 22.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 17\n",
      "Environment.reset(): Trial set up with start = (2, 6), destination = (5, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.9866580837090146, 'right': -0.45804179227981967, None: 0.0, 'left': -0.9541899255627395}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -0.9866580837090146, 'right': -0.45804179227981967, None: 0.0, 'left': -0.959916184867397}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -0.9866580837090146, 'right': -0.45804179227981967, None: 0.0, 'left': -0.9643699421043528}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:13\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.9866580837090146, 'right': -0.4430282150849215, None: 0.0, 'left': -0.9643699421043528}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 26.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:15\n",
      "0.0625 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 18\n",
      "Environment.reset(): Trial set up with start = (8, 5), destination = (2, 6), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (2, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', 'forward', None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', 'forward', None)\n",
      "t:2\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', 'forward', None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', 'forward', None)\n",
      "t:3\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': -0.3333333333333333}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', 'forward', None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', 'forward', None)\n",
      "t:4\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': -0.5}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', 'forward', None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -0.9866580837090146, 'right': -0.4430282150849215, None: 0.0, 'left': -0.966745279297396}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 20.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 19\n",
      "Environment.reset(): Trial set up with start = (8, 3), destination = (1, 1), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (1, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "{'forward': -0.9866580837090146, 'right': -0.4430282150849215, None: 0.0, 'left': -0.9704402482643519}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.0217391304348\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.7626953125}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.0222222222222\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.88134765625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0227272727273\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0232558139535\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0238095238095\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.9866580837090146, 'right': -0.5, None: 0.0, 'left': -0.9704402482643519}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -0.9866580837090146, 'right': -0.5, None: 0.0, 'left': -0.9704402482643519}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -0.9879922753381132, 'right': -0.5, None: 0.0, 'left': -0.9704402482643519}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.88134765625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.88134765625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.88134765625}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.88134765625}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:15\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', 'left', None)\n",
      "t:18\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': -0.08333333333333333}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:19\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:20\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "{'forward': -0.9879922753381132, 'right': -0.5, None: 0.0, 'left': -0.9704402482643519}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 15.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:23\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:24\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:24\n",
      "0.04 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:25\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 21.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 26\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 23.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:26\n",
      "0.037037037037 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 27\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "{'forward': -0.9879922753381132, 'right': -0.4963189946906971, None: 0.0, 'left': -0.9704402482643519}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 22.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "0.0357142857143 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 28\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:28\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 24.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:28\n",
      "0.0344827586207 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 29\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:29\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 26.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "0.0333333333333 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 30\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:30\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 38.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:30\n",
      "0.0322580645161 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 20\n",
      "Environment.reset(): Trial set up with start = (8, 5), destination = (2, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (2, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.9879922753381132, 'right': -0.4963189946906971, None: 0.0, 'left': -0.9714959536834822}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.9879922753381132, 'right': -0.4963189946906971, None: 0.0, 'left': -0.9714959536834822}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -0.9879922753381132, 'right': -0.48151740673141163, None: 0.0, 'left': -0.9714959536834822}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.88134765625}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.5, None: 0.0, 'left': -0.88134765625}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -0.9879922753381132, 'right': -0.48415777719835285, None: 0.0, 'left': -0.9714959536834822}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.9879922753381132, 'right': -0.48415777719835285, None: 0.0, 'left': -0.9714959536834822}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -0.9879922753381132, 'right': -0.48415777719835285, None: 0.0, 'left': -0.9714959536834822}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:19\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 26.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:19\n",
      "0.05 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 21\n",
      "Environment.reset(): Trial set up with start = (3, 6), destination = (4, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (4, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.9886593711526624, 'right': -0.48415777719835285, None: 0.0, 'left': -0.9714959536834822}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.9924395807684416, 'right': -0.48415777719835285, None: 0.0, 'left': -0.9714959536834822}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 22\n",
      "Environment.reset(): Trial set up with start = (4, 1), destination = (8, 5), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (8, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.9939516646147533, 'right': -0.48415777719835285, None: 0.0, 'left': -0.9714959536834822}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.9959677764098356, 'right': -0.48415777719835285, None: 0.0, 'left': -0.9714959536834822}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.9959677764098356, 'right': -0.48415777719835285, None: 0.0, 'left': -0.9786219652626116}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 16.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.9962557923805616, 'right': -0.4785461766432173, None: 0.0, 'left': -0.9786219652626116}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 16.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 20.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 22.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 34.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 23\n",
      "Environment.reset(): Trial set up with start = (2, 1), destination = (8, 1), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (8, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.9962557923805616, 'right': -0.4748780657361314, None: 0.0, 'left': -0.9786219652626116}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.9981278961902809, 'right': -0.4748780657361314, None: 0.0, 'left': -0.9786219652626116}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -0.9981278961902809, 'right': -0.4591686396890782, None: 0.0, 'left': -0.9786219652626116}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'left', None, 'right')\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.49099798872626715, None: 0.0, 'left': -0.88134765625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.49099798872626715, None: 0.0, 'left': -0.88134765625}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 20.5\n",
      "The new state is: ('green', None, None, 'right')\n",
      "t:12\n",
      "0.0769230769231 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 24\n",
      "Environment.reset(): Trial set up with start = (4, 1), destination = (8, 5), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (8, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.49099798872626715, None: 0.0, 'left': -0.8912353515625}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.49099798872626715, None: 0.0, 'left': -0.8912353515625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.49099798872626715, None: 0.0, 'left': -0.8912353515625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.49099798872626715, None: 0.0, 'left': -0.8912353515625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.9985736351925949, 'right': -0.4591686396890782, None: 0.0, 'left': -0.9786219652626116}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.49099798872626715, None: 0.0, 'left': -0.8912353515625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.49099798872626715, None: 0.0, 'left': -0.8912353515625}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -0.9985736351925949, 'right': -0.45438918588495225, None: 0.0, 'left': -0.9786219652626116}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -0.9985736351925949, 'right': -0.45438918588495225, None: 0.0, 'left': -0.9786219652626116}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.9985736351925949, 'right': -0.45438918588495225, None: 0.0, 'left': -0.9801489677438536}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "{'forward': -0.9985736351925949, 'right': -0.45438918588495225, None: 0.0, 'left': -0.9814723698942633}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:18\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -0.9985736351925949, 'right': -0.45438918588495225, None: 0.0, 'left': -0.9826303467758719}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "{'forward': -0.9985736351925949, 'right': -0.45438918588495225, None: 0.0, 'left': -0.9826303467758719}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:22\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:23\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:24\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 12.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:24\n",
      "0.04 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:25\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 26\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:26\n",
      "{'forward': -0.9986306897848911, 'right': -0.451882456389457, None: 0.0, 'left': -0.9832984103614153}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:26\n",
      "0.037037037037 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 27\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:27\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "0.0357142857143 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 28\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "{'forward': -0.9986306897848911, 'right': -0.451882456389457, None: 0.0, 'left': -0.9832984103614153}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "0.0344827586207 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 29\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "{'forward': -0.9986306897848911, 'right': -0.451882456389457, None: 0.0, 'left': -0.9832984103614153}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "0.0333333333333 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 30\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:30\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:30\n",
      "0.0322580645161 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 31\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:31\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 27.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:31\n",
      "0.03125 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 31\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 25\n",
      "Environment.reset(): Trial set up with start = (5, 1), destination = (1, 1), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (1, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.9986306897848911, 'right': -0.451882456389457, None: 0.0, 'left': -0.9832984103614153}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.48564818985364044, None: 0.0, 'left': -0.8912353515625}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 21.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 26\n",
      "Environment.reset(): Trial set up with start = (3, 1), destination = (7, 5), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (7, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.9986306897848911, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9832984103614153}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.9986306897848911, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9874738077710614}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 21.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:7\n",
      "0.125 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 27\n",
      "Environment.reset(): Trial set up with start = (2, 6), destination = (3, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (3, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4549056061118253, None: 0.0, 'left': -0.8912353515625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4549056061118253, None: 0.0, 'left': -0.8912353515625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4549056061118253, None: 0.0, 'left': -0.8912353515625}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -0.9986306897848911, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9874738077710614}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -0.998858908154076, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9874738077710614}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.998858908154076, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9892632638037671}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -0.998858908154076, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9892632638037671}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, 'right')\n",
      "t:9\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'forward', None, 'right')\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 28\n",
      "Environment.reset(): Trial set up with start = (5, 1), destination = (8, 5), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (8, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.998858908154076, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9904562344922374}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.998858908154076, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9904562344922374}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.998858908154076, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9936374896614917}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.998858908154076, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9936374896614917}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -0.998858908154076, 'right': -0.4759412281947285, None: 0.0, 'left': -0.9944328034538052}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -0.998858908154076, 'right': -0.46806148593761315, None: 0.0, 'left': -0.9944328034538052}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -0.9989466844499164, 'right': -0.46806148593761315, None: 0.0, 'left': -0.9944328034538052}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 20.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:19\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 32.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:19\n",
      "0.05 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 29\n",
      "Environment.reset(): Trial set up with start = (1, 5), destination = (6, 3), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (6, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.46617920458386897, None: 0.0, 'left': -0.8912353515625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.46617920458386897, None: 0.0, 'left': -0.8912353515625}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.46617920458386897, None: 0.0, 'left': -0.8912353515625}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.9989466844499164, 'right': -0.4620839864472226, None: 0.0, 'left': -0.9944328034538052}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.9989466844499164, 'right': -0.4620839864472226, None: 0.0, 'left': -0.9958246025903539}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.47745280305591264, None: 0.0, 'left': -0.8912353515625}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.47745280305591264, None: 0.0, 'left': -0.8912353515625}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'forward', None, 'right')\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -0.9989466844499164, 'right': -0.4620839864472226, None: 0.0, 'left': -0.9958246025903539}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -0.9989466844499164, 'right': -0.4620839864472226, None: 0.0, 'left': -0.9958246025903539}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -0.9990424404090149, 'right': -0.4620839864472226, None: 0.0, 'left': -0.9958246025903539}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -3.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:14\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "{'forward': -0.9990424404090149, 'right': -0.4620839864472226, None: 0.0, 'left': -0.9958246025903539}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -0.9990424404090149, 'right': -0.4620839864472226, None: 0.0, 'left': -0.996070214202686}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.48027120267392354, None: 0.0, 'left': -0.8912353515625}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.48027120267392354, None: 0.0, 'left': -0.896959806743421}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:22\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 30\n",
      "Environment.reset(): Trial set up with start = (2, 4), destination = (4, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (4, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.9990424404090149, 'right': -0.4641904316445991, None: 0.0, 'left': -0.996070214202686}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -0.9993616269393433, 'right': -0.4641904316445991, None: 0.0, 'left': -0.996070214202686}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 23.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 31\n",
      "Environment.reset(): Trial set up with start = (8, 4), destination = (4, 2), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (4, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.47527628241473613, None: 0.0, 'left': -0.9175678453947369}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.47527628241473613, None: 0.0, 'left': -0.9175678453947369}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 19.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 32\n",
      "Environment.reset(): Trial set up with start = (2, 6), destination = (5, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 33\n",
      "Environment.reset(): Trial set up with start = (5, 1), destination = (1, 4), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (1, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.47527628241473613, None: 0.0, 'left': -0.9293438674812031}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 23.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 34\n",
      "Environment.reset(): Trial set up with start = (8, 2), destination = (5, 6), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (5, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.9993616269393433, 'right': -0.4529902760680182, None: 0.0, 'left': -0.996070214202686}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.47527628241473613, None: 0.0, 'left': -0.9434750939849625}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.47527628241473613, None: 0.0, 'left': -0.9623167293233084}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -0.9993616269393433, 'right': -0.4764951380340091, None: 0.0, 'left': -0.996070214202686}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -0.9993616269393433, 'right': -0.4764951380340091, None: 0.0, 'left': -0.996070214202686}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -0.9993616269393433, 'right': -0.4764951380340091, None: 0.0, 'left': -0.996070214202686}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 35\n",
      "Environment.reset(): Trial set up with start = (3, 3), destination = (8, 6), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (8, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.9993616269393433, 'right': -0.4679378275926897, None: 0.0, 'left': -0.996070214202686}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.9993616269393433, 'right': -0.43766961358079104, None: 0.0, 'left': -0.996070214202686}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -0.9995212202045074, 'right': -0.43766961358079104, None: 0.0, 'left': -0.996070214202686}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'forward', None, 'forward')\n",
      "t:6\n",
      "0.142857142857 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, 'forward')\n",
      "t:7\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'forward', None, 'forward')\n",
      "t:7\n",
      "0.125 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = None, reward = 0.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -0.9995212202045074, 'right': -0.43766961358079104, None: 0.0, 'left': -0.9968561713621489}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -0.999574417959562, 'right': -0.43766961358079104, None: 0.0, 'left': -0.9968561713621489}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:10\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 36\n",
      "Environment.reset(): Trial set up with start = (3, 2), destination = (2, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.999574417959562, 'right': -0.43410276885345295, None: 0.0, 'left': -0.9968561713621489}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 37\n",
      "Environment.reset(): Trial set up with start = (7, 1), destination = (4, 2), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -0.999716278639708, 'right': -0.43410276885345295, None: 0.0, 'left': -0.9968561713621489}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -0.999716278639708, 'right': -0.43410276885345295, None: 0.0, 'left': -0.9968561713621489}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -0.999716278639708, 'right': -0.43410276885345295, None: 0.0, 'left': -0.9979041142414327}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.47527628241473613, None: 0.0, 'left': -0.9623167293233084}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.47527628241473613, None: 0.0, 'left': -0.9670271381578948}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.47527628241473613, None: 0.0, 'left': -0.9706907894736843}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -0.999716278639708, 'right': -0.4155870874288139, None: 0.0, 'left': -0.9979041142414327}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -0.9997381033597306, 'right': -0.4155870874288139, None: 0.0, 'left': -0.9979041142414327}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -0.999756810262607, 'right': -0.4155870874288139, None: 0.0, 'left': -0.9979041142414327}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "{'forward': -0.9997730229117665, 'right': -0.4155870874288139, None: 0.0, 'left': -0.9979041142414327}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -0.9997730229117665, 'right': -0.4155870874288139, None: 0.0, 'left': -0.9980144240181994}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 38\n",
      "Environment.reset(): Trial set up with start = (5, 5), destination = (8, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (8, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "{'forward': -0.9997730229117665, 'right': -0.4155870874288139, None: 0.0, 'left': -0.9980144240181994}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4155870874288139, None: 0.0, 'left': -0.9980144240181994}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4155870874288139, None: 0.0, 'left': -0.9980144240181994}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, 'right')\n",
      "t:4\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('green', 'left', None, 'right')\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': 'right'}, action = None, reward = 0.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.4598762103453166, None: 0.0, 'left': -0.9706907894736843}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.4598762103453166, None: 0.0, 'left': -0.9706907894736843}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4598762103453166, None: 0.0, 'left': -0.9706907894736843}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4598762103453166, None: 0.0, 'left': -0.9743544407894738}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4598762103453166, None: 0.0, 'left': -0.9743544407894738}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -5.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.4031427686470342, None: 0.0, 'left': -0.9980144240181994}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.4031427686470342, None: 0.0, 'left': -0.9980144240181994}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.4031427686470342, None: 0.0, 'left': -0.9980144240181994}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -1.0, 'right': -0.4031427686470342, None: 0.0, 'left': -0.9981467957503194}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:19\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:19\n",
      "0.05 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 39\n",
      "Environment.reset(): Trial set up with start = (1, 6), destination = (7, 1), deadline = 55\n",
      "RoutePlanner.route_to(): destination = (7, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0178571428571\n",
      "LearningAgent.update(): deadline = 55, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0181818181818\n",
      "LearningAgent.update(): deadline = 54, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4031427686470342, None: 0.0, 'left': -0.9982497515419683}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0185185185185\n",
      "LearningAgent.update(): deadline = 53, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4031427686470342, None: 0.0, 'left': -0.9988331676946456}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0188679245283\n",
      "LearningAgent.update(): deadline = 52, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0192307692308\n",
      "LearningAgent.update(): deadline = 51, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0196078431373\n",
      "LearningAgent.update(): deadline = 50, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.02\n",
      "LearningAgent.update(): deadline = 49, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4031427686470342, None: 0.0, 'left': -0.9988331676946456}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0204081632653\n",
      "LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.44565654325403015, None: 0.0, 'left': -0.9743544407894738}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0208333333333\n",
      "LearningAgent.update(): deadline = 47, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.44565654325403015, None: 0.0, 'left': -0.9772039473684211}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0212765957447\n",
      "LearningAgent.update(): deadline = 46, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0217391304348\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0222222222222\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0227272727273\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:13\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0232558139535\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0238095238095\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "{'forward': -1.0, 'right': -0.44669220168403145, None: 0.0, 'left': -0.9772039473684211}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "0.0625 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "{'forward': -1.0, 'right': -0.44669220168403145, None: 0.0, 'left': -0.9772039473684211}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "{'forward': -1.0, 'right': -0.44669220168403145, None: 0.0, 'left': -0.9772039473684211}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:18\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:19\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:20\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:21\n",
      "{'forward': -1.0, 'right': -0.44671316185310617, None: 0.0, 'left': -0.9772039473684211}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:22\n",
      "{'forward': -1.0, 'right': -0.44671316185310617, None: 0.0, 'left': -0.9772039473684211}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:23\n",
      "{'forward': -1.0, 'right': -0.44671316185310617, None: 0.0, 'left': -0.9781950800915332}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:24\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:24\n",
      "0.04 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 26\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "0.037037037037 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 27\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "{'forward': -1.0, 'right': -0.4152499225661549, None: 0.0, 'left': -0.9988331676946456}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 18.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:27\n",
      "0.0357142857143 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 28\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:28\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 20.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:28\n",
      "0.0344827586207 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 29\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:29\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 22.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:29\n",
      "0.0333333333333 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 30\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:30\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 24.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:30\n",
      "0.0322580645161 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 31\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:31\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 36.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:31\n",
      "0.03125 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 31\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 40\n",
      "Environment.reset(): Trial set up with start = (2, 3), destination = (7, 5), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (7, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4155896243216191, None: 0.0, 'left': -0.9988331676946456}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.4155896243216191, None: 0.0, 'left': -0.9991248757709842}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'right', 'right', None)\n",
      "t:13\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -0.5\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 18.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "0.0625 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:16\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 30.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:16\n",
      "0.0588235294118 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 41\n",
      "Environment.reset(): Trial set up with start = (4, 6), destination = (6, 2), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4159937602199433, None: 0.0, 'left': -0.9991248757709842}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4159937602199433, None: 0.0, 'left': -0.9997082919236615}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4159937602199433, None: 0.0, 'left': -0.9997082919236615}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 42\n",
      "Environment.reset(): Trial set up with start = (2, 1), destination = (3, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (3, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4327950081759546, None: 0.0, 'left': -0.9997082919236615}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4327950081759546, None: 0.0, 'left': -0.9997812189427462}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.4327950081759546, None: 0.0, 'left': -0.999824975154197}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:7\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.4327950081759546, None: 0.0, 'left': -0.999824975154197}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'right', 'left', None)\n",
      "t:12\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'right', 'left', None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'right', 'left', None)\n",
      "t:13\n",
      "{'forward': 0, 'right': 0, None: 0.0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -0.5\n",
      "Total Reward 10.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 18.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.4267432919760649, None: 0.0, 'left': -0.999824975154197}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 18.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.4267432919760649, None: 0.0, 'left': -0.999824975154197}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 18.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 18.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:21\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:22\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:23\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:24\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 21.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:24\n",
      "0.04 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:25\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 21.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:25\n",
      "0.0384615384615 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 43\n",
      "Environment.reset(): Trial set up with start = (4, 6), destination = (8, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (8, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4267432919760649, None: 0.0, 'left': -0.999824975154197}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.44671316185310617, None: 0.0, 'left': -0.9781950800915332}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', 'forward', None)\n",
      "t:5\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', 'forward', None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4366976634576264, None: 0.0, 'left': -0.9781950800915332}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.4366976634576264, None: 0.0, 'left': -0.9781950800915332}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.4366976634576264, None: 0.0, 'left': -0.9781950800915332}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 20.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 44\n",
      "Environment.reset(): Trial set up with start = (8, 5), destination = (5, 3), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (5, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.999824975154197}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.999824975154197}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.9998833167694647}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.9998999858023985}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.9999124875770986}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.9999222111796431}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 45\n",
      "Environment.reset(): Trial set up with start = (2, 4), destination = (8, 1), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (8, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0217391304348\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.9999299900616788}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0222222222222\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.9999299900616788}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0227272727273\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.999953326707786}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0232558139535\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0238095238095\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.4633716459880325, None: 0.0, 'left': -0.999953326707786}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4366976634576264, None: 0.0, 'left': -0.9800121567505721}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:9\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.46947637165669376, None: 0.0, 'left': -0.999953326707786}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.46947637165669376, None: 0.0, 'left': -0.9999575697343509}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.4366976634576264, None: 0.0, 'left': -0.9822330282227307}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.4366976634576264, None: 0.0, 'left': -0.9822330282227307}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('green', 'forward', None, 'left')\n",
      "t:16\n",
      "0.0588235294118 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'forward', None, 'left')\n",
      "t:17\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999575697343509}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999596912476334}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999615234636501}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999631963565349}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:24\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:24\n",
      "0.04 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:25\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 26\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "0.037037037037 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 27\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999631963565349}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "0.0357142857143 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 28\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999631963565349}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "0.0344827586207 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 29\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999631963565349}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "0.0333333333333 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 30\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:30\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:30\n",
      "0.0322580645161 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0\n",
      "New_time 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 31\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:31\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999631963565349}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:31\n",
      "0.03125 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 31\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 32\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:32\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999631963565349}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:32\n",
      "0.030303030303 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 33\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:33\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 21.5\n",
      "The new state is: ('red', None, 'forward', None)\n",
      "t:33\n",
      "0.0294117647059 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 33\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 46\n",
      "Environment.reset(): Trial set up with start = (3, 2), destination = (4, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999631963565349}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.999967796811968}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.999967796811968}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 20.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 47\n",
      "Environment.reset(): Trial set up with start = (4, 5), destination = (5, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (5, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4368902545959345, None: 0.0, 'left': -0.9822330282227307}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4368902545959345, None: 0.0, 'left': -0.9822330282227307}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4368902545959345, None: 0.0, 'left': -0.9822330282227307}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.999967796811968}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999713749439716}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999713749439716}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.4720200073519693, None: 0.0, 'left': -0.9999713749439716}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:13\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'right', None, 'forward')\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'right', None, 'forward')\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.4301261850695774, None: 0.0, 'left': -0.9822330282227307}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:19\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:21\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:22\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 21.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:23\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 20.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:24\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 22.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:24\n",
      "0.04 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:25\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 24.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:25\n",
      "0.0384615384615 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 48\n",
      "Environment.reset(): Trial set up with start = (7, 6), destination = (1, 6), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (1, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.463000406349933, None: 0.0, 'left': -0.9999713749439716}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.463000406349933, None: 0.0, 'left': -0.9999785312079787}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.463000406349933, None: 0.0, 'left': -0.9999785312079787}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.463000406349933, None: 0.0, 'left': -0.9999821093399823}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.463000406349933, None: 0.0, 'left': -0.9999840971910954}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 49\n",
      "Environment.reset(): Trial set up with start = (2, 1), destination = (4, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (4, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.463000406349933, None: 0.0, 'left': -0.9999856874719858}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.463000406349933, None: 0.0, 'left': -0.9999928437359928}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 50\n",
      "Environment.reset(): Trial set up with start = (7, 6), destination = (4, 4), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (4, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.42044563395579193, None: 0.0, 'left': -0.9822330282227307}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.42044563395579193, None: 0.0, 'left': -0.9857864225781847}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 20.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 51\n",
      "Environment.reset(): Trial set up with start = (4, 1), destination = (3, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (3, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.43370469496315994, None: 0.0, 'left': -0.9857864225781847}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.43370469496315994, None: 0.0, 'left': -0.9928932112890924}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.43370469496315994, None: 0.0, 'left': -0.9928932112890924}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.44548692389448685, None: 0.0, 'left': -0.9999928437359928}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.44548692389448685, None: 0.0, 'left': -0.9999928437359928}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.44548692389448685, None: 0.0, 'left': -0.9999928437359928}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.44548692389448685, None: 0.0, 'left': -0.9999928437359928}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.44548692389448685, None: 0.0, 'left': -0.9999942749887943}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 52\n",
      "Environment.reset(): Trial set up with start = (6, 6), destination = (2, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.44548692389448685, None: 0.0, 'left': -0.9999947520730614}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.43370469496315994, None: 0.0, 'left': -0.9928932112890924}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.43370469496315994, None: 0.0, 'left': -0.9928932112890924}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.43370469496315994, None: 0.0, 'left': -0.9928932112890924}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.43370469496315994, None: 0.0, 'left': -0.9928932112890924}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:13\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 22.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:13\n",
      "0.0714285714286 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 53\n",
      "Environment.reset(): Trial set up with start = (7, 4), destination = (5, 6), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4211799098215144, None: 0.0, 'left': -0.9999947520730614}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4211799098215144, None: 0.0, 'left': -0.9999947520730614}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 54\n",
      "Environment.reset(): Trial set up with start = (1, 5), destination = (5, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4211799098215144, None: 0.0, 'left': -0.9999947520730614}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'left', 'left', None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'left', 'left', None)\n",
      "t:2\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4218609644728719, None: 0.0, 'left': -0.9928932112890924}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.46058995491075716, None: 0.0, 'left': -0.9999947520730614}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.41361794557687614, None: 0.0, 'left': -0.9928932112890924}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.41361794557687614, None: 0.0, 'left': -0.9936038901601831}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.41361794557687614, None: 0.0, 'left': -0.9936038901601831}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.4649688488095619, None: 0.0, 'left': -0.9999947520730614}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.4649688488095619, None: 0.0, 'left': -0.9999951269249856}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "{'forward': -1.0, 'right': -0.4649688488095619, None: 0.0, 'left': -0.9999951269249856}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.4649688488095619, None: 0.0, 'left': -0.9999951269249856}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 55\n",
      "Environment.reset(): Trial set up with start = (1, 1), destination = (5, 6), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (5, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0217391304348\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0222222222222\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4161648508135282, None: 0.0, 'left': -0.9999951269249856}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0227272727273\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.41361794557687614, None: 0.0, 'left': -0.9941368993135012}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0232558139535\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.41361794557687614, None: 0.0, 'left': -0.9941368993135012}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.0238095238095\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'right', 'forward', None)\n",
      "t:5\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', 'forward', None)\n",
      "t:5\n",
      "0.166666666667 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:7\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:8\n",
      "{'forward': -0.3333333333333333, 'right': 0, None: 0, 'left': -0.4}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', 'left', None)\n",
      "t:8\n",
      "0.111111111111 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:9\n",
      "{'forward': -0.3333333333333333, 'right': 0, None: 0, 'left': -0.4666666666666667}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', 'left', None)\n",
      "t:9\n",
      "0.1 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:10\n",
      "{'forward': -0.4, 'right': 0, None: 0, 'left': -0.4666666666666667}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.4211305177505153, None: 0.0, 'left': -0.9941368993135012}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:13\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:14\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.4441099005423522, None: 0.0, 'left': -0.9999951269249856}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 31.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:21\n",
      "0.0454545454545 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 56\n",
      "Environment.reset(): Trial set up with start = (6, 3), destination = (2, 4), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (2, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:2\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4441099005423522, None: 0.0, 'left': -0.9999951269249856}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4441099005423522, None: 0.0, 'left': -0.9999951269249856}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, 'forward')\n",
      "t:5\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4552879204338818, None: 0.0, 'left': -0.9999951269249856}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4552879204338818, None: 0.0, 'left': -0.9999956683777649}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:11\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.4552879204338818, None: 0.0, 'left': -0.9999956683777649}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.4552879204338818, None: 0.0, 'left': -0.9999960015794753}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.4552879204338818, None: 0.0, 'left': -0.9999960015794753}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 57\n",
      "Environment.reset(): Trial set up with start = (2, 4), destination = (5, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (5, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 58\n",
      "Environment.reset(): Trial set up with start = (2, 2), destination = (1, 6), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (1, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4228881597898242, None: 0.0, 'left': -0.9941368993135012}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4228881597898242, None: 0.0, 'left': -0.9960912662090009}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4228881597898242, None: 0.0, 'left': -0.9960912662090009}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4552879204338818, None: 0.0, 'left': -0.9999960015794753}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.46087693037964655, None: 0.0, 'left': -0.9999960015794753}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:13\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.46087693037964655, None: 0.0, 'left': -0.9999960015794753}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 12.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "{'forward': -1.0, 'right': -0.46087693037964655, None: 0.0, 'left': -0.9999960015794753}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -1.0, 'right': -0.46087693037964655, None: 0.0, 'left': -0.9999962367806826}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:18\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.46305043424744396, None: 0.0, 'left': -0.9999962367806826}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:20\n",
      "0.047619047619 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:21\n",
      "{'forward': -1.0, 'right': -0.4228881597898242, None: 0.0, 'left': -0.9960912662090009}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 15.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:22\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:23\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:24\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 21.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:24\n",
      "0.04 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:25\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 23.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 59\n",
      "Environment.reset(): Trial set up with start = (5, 4), destination = (8, 6), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (8, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.46305043424744396, None: 0.0, 'left': -0.9999964249416485}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.46305043424744396, None: 0.0, 'left': -0.9999964249416485}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.46305043424744396, None: 0.0, 'left': -0.9999964249416485}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 8.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.46305043424744396, None: 0.0, 'left': -0.9999964249416485}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:15\n",
      "{'forward': -1.0, 'right': -0.46305043424744396, None: 0.0, 'left': -0.9999966632788719}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 12.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:17\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:18\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:19\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 18.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "{'forward': -1.0, 'right': -0.4535608546398998, None: 0.0, 'left': -0.9999966632788719}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 17.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:21\n",
      "{'forward': -0.4, 'right': -0.045454545454545456, None: 0, 'left': -0.4666666666666667}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 16.5\n",
      "The new state is: ('red', 'forward', 'left', None)\n",
      "t:21\n",
      "0.0454545454545 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:22\n",
      "{'forward': -0.4, 'right': -0.045454545454545456, None: 0, 'left': -0.49090909090909096}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 15.5\n",
      "The new state is: ('red', 'forward', 'left', None)\n",
      "t:22\n",
      "0.0434782608696 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'forward', 'left', None)\n",
      "t:23\n",
      "{'forward': -0.4260869565217391, 'right': -0.045454545454545456, None: 0, 'left': -0.49090909090909096}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', 'forward', 'left', None)\n",
      "t:23\n",
      "0.0416666666667 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'forward', 'left', None)\n",
      "t:24\n",
      "{'forward': 0, 'right': -0.021529338700581477, None: 0, 'left': -0.08333333333333333}\n",
      "left\n",
      "REWARD IS: -0.5\n",
      "Total Reward 14.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:24\n",
      "0.04 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 60\n",
      "Environment.reset(): Trial set up with start = (8, 6), destination = (4, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (4, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:2\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4535608546398998, None: 0.0, 'left': -0.9999966632788719}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, 'right')\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4535608546398998, None: 0.0, 'left': -0.9999974974591539}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4535608546398998, None: 0.0, 'left': -0.9999974974591539}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.4535608546398998, None: 0.0, 'left': -0.9999974974591539}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, 'left')\n",
      "t:13\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, 'left')\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'left'}, action = None, reward = 0.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.4535608546398998, None: 0.0, 'left': -0.999997689962296}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:17\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:18\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:19\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "{'forward': -1.0, 'right': -0.44506456950839285, None: 0.0, 'left': -0.999997689962296}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "{'forward': -1.0, 'right': -0.44506456950839285, None: 0.0, 'left': -0.9999977999640914}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "{'forward': -1.0, 'right': -0.44506456950839285, None: 0.0, 'left': -0.9999977999640914}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:24\n",
      "{'forward': -1.0, 'right': -0.44506456950839285, None: 0.0, 'left': -0.9999977999640914}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:24\n",
      "0.04 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:25\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:25\n",
      "0.0384615384615 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 61\n",
      "Environment.reset(): Trial set up with start = (4, 1), destination = (1, 5), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (1, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999977999640914}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999977999640914}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999977999640914}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999977999640914}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999977999640914}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999981142549357}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999981142549357}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999981142549357}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:11\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999983028294421}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999983028294421}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999984240559106}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "0.0625 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:16\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.99999851160836}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.9999985899447621}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:20\n",
      "0.047619047619 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 62\n",
      "Environment.reset(): Trial set up with start = (6, 5), destination = (1, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (1, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.999998660447524}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.999999106965016}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.999999330223762}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.999999330223762}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.999999330223762}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.999999330223762}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.40538636649902354, None: 0.0, 'left': -0.999999330223762}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', 'forward', None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.41327083595743824, None: 0.0, 'left': -0.999999330223762}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.9960912662090009}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:15\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.9963518484617342}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.9963518484617342}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.9963518484617342}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:19\n",
      "0.05 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:20\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "{'forward': -1.0, 'right': -0.41946577624619263, None: 0.0, 'left': -0.999999330223762}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "{'forward': -1.0, 'right': -0.41946577624619263, None: 0.0, 'left': -0.999999330223762}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:24\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:24\n",
      "0.04 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 63\n",
      "Environment.reset(): Trial set up with start = (7, 6), destination = (2, 4), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (2, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.41946577624619263, None: 0.0, 'left': -0.9999993860384484}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.9963518484617342}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.9975678989744896}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.4597328881230963, None: 0.0, 'left': -0.9999993860384484}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4597328881230963, None: 0.0, 'left': -0.9999994737472415}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', 'forward', None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', 'forward', None)\n",
      "t:8\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', 'forward', None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', 'forward', None)\n",
      "t:9\n",
      "{'forward': 0, 'right': 0, None: 0.0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', 'forward', None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 64\n",
      "Environment.reset(): Trial set up with start = (3, 3), destination = (6, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (6, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4647662771077093, None: 0.0, 'left': -0.9999994737472415}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4233028291278863, None: 0.0, 'left': -0.9999994737472415}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.9981759242308672}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.998479936859056}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.998479936859056}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4078998127375506, None: 0.0, 'left': -0.998669944751674}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.4146785331732278, None: 0.0, 'left': -0.9999994737472415}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.4146785331732278, None: 0.0, 'left': -0.999999514228223}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:14\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 65\n",
      "Environment.reset(): Trial set up with start = (8, 1), destination = (2, 5), deadline = 50\n",
      "RoutePlanner.route_to(): destination = (2, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.40628935050591514, None: 0.0, 'left': -0.999999514228223}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0196078431373\n",
      "LearningAgent.update(): deadline = 50, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.40628935050591514, None: 0.0, 'left': -0.999999514228223}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.02\n",
      "LearningAgent.update(): deadline = 49, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.40628935050591514, None: 0.0, 'left': -0.999999514228223}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0204081632653\n",
      "LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0208333333333\n",
      "LearningAgent.update(): deadline = 47, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0212765957447\n",
      "LearningAgent.update(): deadline = 46, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0217391304348\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.40628935050591514, None: 0.0, 'left': -0.999999514228223}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0222222222222\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.40628935050591514, None: 0.0, 'left': -0.999999514228223}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0227272727273\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.40628935050591514, None: 0.0, 'left': -0.999999574949695}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0232558139535\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.40628935050591514, None: 0.0, 'left': -0.9999996221775067}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0238095238095\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.40628935050591514, None: 0.0, 'left': -0.999999659959756}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.405787487865477, None: 0.0, 'left': -0.998669944751674}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.405787487865477, None: 0.0, 'left': -0.998669944751674}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -1.0, 'right': -0.40730632901947983, None: 0.0, 'left': -0.999999659959756}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.40844352073591844, None: 0.0, 'left': -0.998669944751674}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.40844352073591844, None: 0.0, 'left': -0.9987399476594807}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:21\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:22\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:23\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:24\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:24\n",
      "0.04 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 26\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:26\n",
      "0.037037037037 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 27\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "{'forward': -1.0, 'right': -0.4071287285621029, None: 0.0, 'left': -0.999999659959756}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:27\n",
      "0.0357142857143 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 28\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "{'forward': -1.0, 'right': -0.4071287285621029, None: 0.0, 'left': -0.999999659959756}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:28\n",
      "0.0344827586207 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 29\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "{'forward': -1.0, 'right': -0.4071287285621029, None: 0.0, 'left': -0.999999659959756}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:29\n",
      "0.0333333333333 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 30\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:30\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:30\n",
      "0.0322580645161 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 31\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:31\n",
      "{'forward': -1.0, 'right': -0.4071287285621029, None: 0.0, 'left': -0.999999659959756}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:31\n",
      "0.03125 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 31\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 32\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:32\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 28.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:32\n",
      "0.030303030303 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 66\n",
      "Environment.reset(): Trial set up with start = (6, 6), destination = (4, 4), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4071287285621029, None: 0.0, 'left': -0.9999998352930068}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', 'right', None)\n",
      "t:3\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': 'right', 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 67\n",
      "Environment.reset(): Trial set up with start = (7, 5), destination = (6, 2), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (6, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.4071287285621029, None: 0.0, 'left': -0.9999998352930068}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4071287285621029, None: 0.0, 'left': -0.9999998352930068}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4071287285621029, None: 0.0, 'left': -0.9999998352930068}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -2.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'right', None, 'left')\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'right', None, 'left')\n",
      "t:7\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': 0}\n",
      "forward\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9988659528935326}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9988659528935326}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 68\n",
      "Environment.reset(): Trial set up with start = (8, 5), destination = (6, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (6, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4025816492098724, None: 0.0, 'left': -0.9999998352930068}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 16.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 69\n",
      "Environment.reset(): Trial set up with start = (3, 6), destination = (5, 2), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (5, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = None, reward = 0.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9988659528935326}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9988659528935326}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.4025816492098724, None: 0.0, 'left': -0.999999890195338}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.3976699786612816, None: 0.0, 'left': -0.9999999058817184}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.3976699786612816, None: 0.0, 'left': -0.9999999058817184}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 25.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:15\n",
      "0.0625 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 70\n",
      "Environment.reset(): Trial set up with start = (6, 2), destination = (3, 4), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (3, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.3976699786612816, None: 0.0, 'left': -0.9999999058817184}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.3976699786612816, None: 0.0, 'left': -0.9999999058817184}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.3976699786612816, None: 0.0, 'left': -0.9999999529408592}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -2.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.39436259887817904, None: 0.0, 'left': -0.9999999529408592}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.4154900791025432, None: 0.0, 'left': -0.9999999529408592}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4154900791025432, None: 0.0, 'left': -0.9999999596635936}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 71\n",
      "Environment.reset(): Trial set up with start = (2, 1), destination = (7, 1), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (7, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.40987929998294437, None: 0.0, 'left': -0.9999999596635936}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.40987929998294437, None: 0.0, 'left': -0.9999999596635936}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.40987929998294437, None: 0.0, 'left': -0.9999999731090625}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.40987929998294437, None: 0.0, 'left': -0.9999999798317969}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9988659528935326}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.42275368569966665, None: 0.0, 'left': -0.9999999798317969}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.42275368569966665, None: 0.0, 'left': -0.9999999798317969}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.42275368569966665, None: 0.0, 'left': -0.9999999798317969}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:13\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9990077087818411}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:16\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "{'forward': -1.0, 'right': -0.4291908785580278, None: 0.0, 'left': -0.9999999798317969}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:18\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 72\n",
      "Environment.reset(): Trial set up with start = (8, 2), destination = (3, 4), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (3, 4)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', 'forward', None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', 'forward', None)\n",
      "t:4\n",
      "{'forward': 0, 'right': 0, None: 0, 'left': -0.6000000000000001}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', 'forward', None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4291908785580278, None: 0.0, 'left': -0.9999999809522526}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4291908785580278, None: 0.0, 'left': -0.9999999809522526}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4291908785580278, None: 0.0, 'left': -0.9999999809522526}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9990077087818411}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 20.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 73\n",
      "Environment.reset(): Trial set up with start = (2, 2), destination = (7, 5), deadline = 40\n",
      "RoutePlanner.route_to(): destination = (7, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4291908785580278, None: 0.0, 'left': -0.9999999828570274}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4291908785580278, None: 0.0, 'left': -0.9999999828570274}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.4266915292498351, None: 0.0, 'left': -0.9999999885713518}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4266915292498351, None: 0.0, 'left': -0.9999999918366798}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -1.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4253134374372712, None: 0.0, 'left': -0.9999999918366798}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9990903997166877}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9991730906515343}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9992419997639064}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9992419997639064}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9992961426379131}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -3.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward -4.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.42412284653098015, None: 0.0, 'left': -0.9999999918366798}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.42412284653098015, None: 0.0, 'left': -0.9999999918366798}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:22\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:23\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:24\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'right', None, 'right')\n",
      "t:24\n",
      "0.04 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:25\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:25\n",
      "0.0384615384615 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 26\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:26\n",
      "{'forward': -1.0, 'right': -0.4098912384899722, None: 0.0, 'left': -0.9992961426379131}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 8.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:26\n",
      "0.037037037037 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 27\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:27\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:27\n",
      "0.0357142857143 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 28\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:28\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('green', 'right', None, 'right')\n",
      "t:28\n",
      "0.0344827586207 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 29\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:29\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 14.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:29\n",
      "0.0333333333333 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 30\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:30\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 26.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:30\n",
      "0.0322580645161 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 74\n",
      "Environment.reset(): Trial set up with start = (1, 6), destination = (6, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (6, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.42412284653098015, None: 0.0, 'left': -0.9999999922448458}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.42412284653098015, None: 0.0, 'left': -0.9999999922448458}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.42412284653098015, None: 0.0, 'left': -0.9999999941836344}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.42412284653098015, None: 0.0, 'left': -0.9999999941836344}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.4081387603442581, None: 0.0, 'left': -0.9992961426379131}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4081387603442581, None: 0.0, 'left': -0.9993743490114784}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:13\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 23.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 75\n",
      "Environment.reset(): Trial set up with start = (4, 1), destination = (8, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (8, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.43360749071460764, None: 0.0, 'left': -0.9999999941836344}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.43360749071460764, None: 0.0, 'left': -0.9999999970918172}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.40077237782462155, None: 0.0, 'left': -0.9993743490114784}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.45573832714307183, None: 0.0, 'left': -0.9999999970918172}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.4071172023500598, None: 0.0, 'left': -0.9993743490114784}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:12\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.45573832714307183, None: 0.0, 'left': -0.9999999970918172}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.45573832714307183, None: 0.0, 'left': -0.9999999970918172}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.44495868165949914, None: 0.0, 'left': -0.9999999970918172}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 14.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.44495868165949914, None: 0.0, 'left': -0.9999999972448794}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:19\n",
      "0.05 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "{'forward': -1.0, 'right': -0.44495868165949914, None: 0.0, 'left': -0.9999999972448794}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:20\n",
      "0.047619047619 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:21\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 25.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:21\n",
      "0.0454545454545 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 76\n",
      "Environment.reset(): Trial set up with start = (6, 4), destination = (3, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (3, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 12.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 24.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 77\n",
      "Environment.reset(): Trial set up with start = (6, 2), destination = (1, 6), deadline = 45\n",
      "RoutePlanner.route_to(): destination = (1, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.4148574354875548, None: 0.0, 'left': -0.9993743490114784}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.0217391304348\n",
      "LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.0222222222222\n",
      "LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4148574354875548, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0227272727273\n",
      "LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4148574354875548, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0232558139535\n",
      "LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0238095238095\n",
      "LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.44495868165949914, None: 0.0, 'left': -0.9999999972448794}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0243902439024\n",
      "LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.025\n",
      "LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.4404521624380434, None: 0.0, 'left': -0.9999999972448794}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.025641025641\n",
      "LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0263157894737\n",
      "LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.43773456764490337, None: 0.0, 'left': -0.9999999972448794}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.027027027027\n",
      "LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.43773456764490337, None: 0.0, 'left': -0.9999999972448794}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.43773456764490337, None: 0.0, 'left': -0.9999999972448794}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:13\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:14\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 17.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:14\n",
      "0.0666666666667 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 78\n",
      "Environment.reset(): Trial set up with start = (1, 3), destination = (4, 2), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4148574354875548, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 79\n",
      "Environment.reset(): Trial set up with start = (8, 6), destination = (1, 6), deadline = 35\n",
      "RoutePlanner.route_to(): destination = (1, 6)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0277777777778\n",
      "LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0285714285714\n",
      "LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0294117647059\n",
      "LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.030303030303\n",
      "LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.03125\n",
      "LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.43564587492938095, None: 0.0, 'left': -0.9999999972448794}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.43564587492938095, None: 0.0, 'left': -0.9999999972448794}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.4148574354875548, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "{'forward': -1.0, 'right': -0.4148574354875548, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.4148574354875548, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:15\n",
      "0.0625 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:18\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = right, reward = 2.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:19\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 27.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:19\n",
      "0.05 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 80\n",
      "Environment.reset(): Trial set up with start = (5, 6), destination = (2, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (2, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 22.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 81\n",
      "Environment.reset(): Trial set up with start = (3, 2), destination = (6, 1), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (6, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.43564587492938095, None: 0.0, 'left': -0.9999999975510039}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.43564587492938095, None: 0.0, 'left': -1.0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.43564587492938095, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.43564587492938095, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.43564587492938095, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.41102801227274316, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.41102801227274316, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.41102801227274316, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.41102801227274316, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'right', 'forward', None)\n",
      "t:11\n",
      "0.0833333333333 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:13\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:15\n",
      "left\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:15\n",
      "0.0625 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = left, reward = 12.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 82\n",
      "Environment.reset(): Trial set up with start = (3, 3), destination = (7, 2), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (7, 2)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.43564587492938095, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:4\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = left, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.35061623011486237, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.35061623011486237, None: 0.0, 'left': -1.0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.35061623011486237, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'left', 'right', None)\n",
      "t:11\n",
      "{'forward': 0, 'right': 0, None: 0.0, 'left': 0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 1.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': 'right', 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:13\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:14\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:18\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:19\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'right', 'right', None)\n",
      "t:20\n",
      "0.047619047619 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:21\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:22\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:23\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 11.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:24\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:24\n",
      "0.04 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:25\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:25\n",
      "0.0384615384615 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 83\n",
      "Environment.reset(): Trial set up with start = (4, 2), destination = (7, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:2\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.35061623011486237, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "{'forward': -1.0, 'right': -0.35061623011486237, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 17.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 84\n",
      "Environment.reset(): Trial set up with start = (1, 4), destination = (4, 5), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (4, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:3\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 85\n",
      "Environment.reset(): Trial set up with start = (6, 6), destination = (7, 1), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (7, 1)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "{'forward': -1.0, 'right': -0.3362155236608835, None: 0.0, 'left': -1.0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:8\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "{'forward': -1.0, 'right': -0.3362155236608835, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:11\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('red', None, None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 86\n",
      "Environment.reset(): Trial set up with start = (6, 4), destination = (2, 3), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (2, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:2\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.3362155236608835, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.3362155236608835, None: 0.0, 'left': -1.0}\n",
      "forward\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.3362155236608835, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:9\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 18.5\n",
      "The new state is: ('red', None, None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 87\n",
      "Environment.reset(): Trial set up with start = (4, 5), destination = (2, 3), deadline = 20\n",
      "RoutePlanner.route_to(): destination = (2, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:0\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:1\n",
      "0.5 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:2\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.35441379880967416, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "0.25 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 5.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:4\n",
      "0.2 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:5\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 7.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 8.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:7\n",
      "0.125 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:8\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 22.5\n",
      "The new state is: ('green', None, None, None)\n",
      "t:9\n",
      "0.1 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 88\n",
      "Environment.reset(): Trial set up with start = (6, 1), destination = (8, 5), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (8, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:2\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:3\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:4\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:5\n",
      "{'forward': -1.0, 'right': -0.35040630870321526, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 7.5\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:7\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 9.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 11.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:9\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 13.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "RANDOM ACTION\n",
      "REWARD IS: -0.5\n",
      "Total Reward 13.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:11\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 15.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 17.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:13\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 19.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:14\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 21.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:15\n",
      "forward\n",
      "Environment.act(): Primary agent has reached destination!\n",
      "REWARD IS: 12.0\n",
      "Total Reward 33.0\n",
      "The new state is: ('green', None, None, None)\n",
      "t:15\n",
      "0.0625 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 12.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulator.run(): Trial 89\n",
      "Environment.reset(): Trial set up with start = (1, 5), destination = (6, 5), deadline = 25\n",
      "RoutePlanner.route_to(): destination = (6, 5)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:0\n",
      "1.0 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:1\n",
      "0.5 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:3\n",
      "0.25 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward -3.0\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:4\n",
      "0.2 0.0454545454545\n",
      "LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:5\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward -1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.047619047619\n",
      "LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "RANDOM ACTION\n",
      "REWARD IS: 2.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "0.142857142857 0.05\n",
      "LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:7\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0526315789474\n",
      "LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.36104810138191246, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0555555555556\n",
      "LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 9\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:9\n",
      "0.1 0.0588235294118\n",
      "LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 10\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "{'forward': -1.0, 'right': -0.36104810138191246, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 3.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:10\n",
      "0.0909090909091 0.0625\n",
      "LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 11\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "{'forward': -1.0, 'right': -0.36104810138191246, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:11\n",
      "0.0833333333333 0.0666666666667\n",
      "LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 12\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "{'forward': -1.0, 'right': -0.36104810138191246, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:12\n",
      "0.0769230769231 0.0714285714286\n",
      "LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 13\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "RANDOM ACTION\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:13\n",
      "0.0714285714286 0.0769230769231\n",
      "LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 14\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:14\n",
      "{'forward': -1.0, 'right': -0.36104810138191246, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:14\n",
      "0.0666666666667 0.0833333333333\n",
      "LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 14\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 15\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:15\n",
      "0.0625 0.0909090909091\n",
      "LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 16\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "None\n",
      "REWARD IS: 0.0\n",
      "Total Reward 0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:16\n",
      "0.0588235294118 0.1\n",
      "LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 17\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:17\n",
      "0.0555555555556 0.111111111111\n",
      "LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 18\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -1.5\n",
      "The new state is: ('red', 'left', None, None)\n",
      "t:18\n",
      "0.0526315789474 0.125\n",
      "LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 19\n",
      "The current state is: ('red', 'left', None, None)\n",
      "t:19\n",
      "{'forward': -1.0, 'right': -0.4184423445833479, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward -2.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:19\n",
      "0.05 0.142857142857\n",
      "LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 20\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:20\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 0.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:20\n",
      "0.047619047619 0.166666666667\n",
      "LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 21\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:21\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:21\n",
      "0.0454545454545 0.2\n",
      "LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 22\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "RANDOM ACTION\n",
      "REWARD IS: 0.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:22\n",
      "0.0434782608696 0.25\n",
      "LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0\n",
      "New_time 22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 23\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "{'forward': -1.0, 'right': -0.3584234096395356, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 1.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:23\n",
      "0.0416666666667 0.333333333333\n",
      "LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 24\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:24\n",
      "{'forward': -1.0, 'right': -0.3584234096395356, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 0.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:24\n",
      "0.04 0.5\n",
      "LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 25\n",
      "The current state is: ('red', 'left', 'forward', None)\n",
      "t:25\n",
      "{'forward': -0.1, 'right': 0, None: 0.0, 'left': 0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward -0.5\n",
      "The new state is: ('red', 'left', 'forward', None)\n",
      "t:25\n",
      "0.0384615384615 1.0\n",
      "LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "11\n",
      "Environment.step(): Primary agent ran out of time! Trial aborted.\n",
      "Simulator.run(): Trial 90\n",
      "Environment.reset(): Trial set up with start = (3, 1), destination = (7, 3), deadline = 30\n",
      "RoutePlanner.route_to(): destination = (7, 3)\n",
      "Old_TIME 0\n",
      "The current state is: ('red', 'right', None, None)\n",
      "t:0\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 2.0\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:0\n",
      "1.0 0.0322580645161\n",
      "LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 1\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:1\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 4.0\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:1\n",
      "0.5 0.0333333333333\n",
      "LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 2\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:2\n",
      "{'forward': -1.0, 'right': -0.3212891273130567, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 3.5\n",
      "The new state is: ('green', 'left', None, None)\n",
      "t:2\n",
      "0.333333333333 0.0344827586207\n",
      "LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 3\n",
      "The current state is: ('green', 'left', None, None)\n",
      "t:3\n",
      "left\n",
      "REWARD IS: 2.0\n",
      "Total Reward 5.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:3\n",
      "0.25 0.0357142857143\n",
      "LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0\n",
      "New_time 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 4\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "{'forward': -1.0, 'right': -0.3562632423806025, None: 0.0, 'left': -1.0}\n",
      "left\n",
      "REWARD IS: -1.0\n",
      "Total Reward 4.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:4\n",
      "0.2 0.037037037037\n",
      "LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0\n",
      "New_time 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 5\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 6.5\n",
      "The new state is: ('green', 'forward', None, None)\n",
      "t:5\n",
      "0.166666666667 0.0384615384615\n",
      "LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 6\n",
      "The current state is: ('green', 'forward', None, None)\n",
      "t:6\n",
      "forward\n",
      "REWARD IS: 2.0\n",
      "Total Reward 8.5\n",
      "The new state is: ('green', 'right', None, None)\n",
      "t:6\n",
      "0.142857142857 0.04\n",
      "LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0\n",
      "New_time 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 7\n",
      "The current state is: ('green', 'right', None, None)\n",
      "t:7\n",
      "right\n",
      "REWARD IS: 2.0\n",
      "Total Reward 10.5\n",
      "The new state is: ('red', 'forward', None, None)\n",
      "t:7\n",
      "0.125 0.0416666666667\n",
      "LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0\n",
      "New_time 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME 8\n",
      "The current state is: ('red', 'forward', None, None)\n",
      "t:8\n",
      "{'forward': -1.0, 'right': -0.3562632423806025, None: 0.0, 'left': -1.0}\n",
      "right\n",
      "REWARD IS: -0.5\n",
      "Total Reward 10.0\n",
      "The new state is: ('red', 'right', None, None)\n",
      "t:8\n",
      "0.111111111111 0.0434782608696\n",
      "LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5\n",
      "New_time 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Old_TIME"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from environment import Agent, Environment\n",
    "from planner import RoutePlanner\n",
    "from simulator import Simulator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class LearningAgent(Agent):\n",
    "    \"\"\"An agent that learns to drive in the smartcab world.\"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super(LearningAgent, self).__init__(env)  # sets self.env = env, state = None, next_waypoint = None, and a default color\n",
    "        self.color = 'red'  # override color\n",
    "        self.planner = RoutePlanner(self.env, self)  # simple route planner to get next_waypoint\n",
    "        # TODO: Initialize any additional variables here\n",
    "        \n",
    "        #Set traffic_light and movement\n",
    "        traffic_light=[\"red\",\"green\"]\n",
    "        motion = [None, 'forward', 'left', 'right']\n",
    "        waypoint,oncoming,left=motion,motion,motion\n",
    "\n",
    "        \n",
    "        #Initialize q_table\n",
    "        #Set all features to 0\n",
    "        self.q_table = {}\n",
    "        for light in traffic_light:\n",
    "            for point in waypoint:\n",
    "                for on in oncoming:\n",
    "                    for lf in left:\n",
    "                        self.q_table[(light, point, on, lf)] = {None: 0, 'forward': 0, 'left': 0, 'right': 0}\n",
    "\n",
    "        print self.q_table\n",
    "\n",
    "\n",
    "        self.episode=0\n",
    "        self.preserve=[]\n",
    "        self.failure=0\n",
    "\n",
    "    def reset(self,destination=None,total=0):\n",
    "\n",
    "        self.planner.route_to(destination)\n",
    "        # TODO: Prepare for a new trip; reset any variables here, if required\n",
    "        self.total_reward=total\n",
    "\n",
    "        \n",
    "    def update(self, t):\n",
    "        # Gather inputs\n",
    "        self.next_waypoint = self.planner.next_waypoint()  # from route planner, also displayed by simulator\n",
    "        inputs = self.env.sense(self)\n",
    "        deadline = self.env.get_deadline(self)\n",
    "        \n",
    "        \n",
    "        old_time=t\n",
    "        print 'Old_TIME',old_time\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "        # TODO: Update state\n",
    "        self.state = (inputs['light'],\n",
    "                      self.next_waypoint,\n",
    "                      inputs['oncoming'],\n",
    "                      inputs['left'])\n",
    "\n",
    "        print \"The current state is: {}\".format(self.state)\n",
    "\n",
    "        print \"t:{}\".format(t)\n",
    "        \n",
    "        # TODO: Select action according to your policy\n",
    "        epsilon=0.1\n",
    "        rand=random.random()\n",
    "        if rand<epsilon:\n",
    "            action=random.choice(Environment.valid_actions[0:])\n",
    "            print \"RANDOM ACTION\"\n",
    "        else:\n",
    "            if max(self.q_table[self.state].values())==0:\n",
    "                action=random.choice(Environment.valid_actions[0:])\n",
    "                print self.q_table[self.state]\n",
    "               \n",
    "            else:\n",
    "                action = max(self.q_table[self.state],\n",
    "                     key=self.q_table[self.state].get)\n",
    "\n",
    "            print action\n",
    "\n",
    "        # Execute action and get reward\n",
    "        reward = self.env.act(self, action)\n",
    "        \n",
    "        print \"REWARD IS:\",reward\n",
    "        self.total_reward+=reward\n",
    "     \n",
    "        print \"Total Reward\",self.total_reward\n",
    "        \n",
    "        # TODO: Learn policy based on state, action, reward\n",
    "        # Set the tuning parameters\n",
    "        alpha = 1.0/(1.0+t) # learning rate\n",
    "        gamma = 1.0/(1.0+deadline) # discount factor\n",
    "      #  alpha=0.5\n",
    "       # gamma=0.2\n",
    "        # Get the new state after the above action\n",
    "\n",
    "        inputs_new = self.env.sense(self)\n",
    "        state_new = (inputs_new['light'],\n",
    "                     self.planner.next_waypoint(),\n",
    "                     inputs_new['oncoming'],\n",
    "                     inputs_new['left'])\n",
    "        print \"The new state is: {}\".format(state_new)\n",
    "        print \"t:{}\".format(t)\n",
    "        print alpha,gamma\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Calculate the Q_value\n",
    "        q_value = (1 - alpha) * self.q_table[self.state][action] + \\\n",
    "                  alpha * (reward + gamma * max(self.q_table[state_new].values()))\n",
    "        # Update the Q_table\n",
    "        self.q_table[self.state][action] = q_value\n",
    "        # Set current state and action as previous state and action\n",
    "        \n",
    "        \n",
    "        print \"LearningAgent.update(): deadline = {}, inputs = {}, action = {}, reward = {}\".format(deadline, inputs, action, reward)  # [debug]\n",
    "        new_time=t\n",
    "        print 'New_time',new_time\n",
    "        total_preserve=self.total_reward\n",
    "        print \"\\n\"\n",
    "        print \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "        if old_time==0:\n",
    "            self.episode+=1\n",
    "            \n",
    "\n",
    "        self.preserve.append([new_time,self.total_reward,deadline,self.episode])\n",
    "      #  self.preserve.append(new_time)\n",
    "      #  self.preserve.append(self.total_reward)\n",
    "      #  self.preserve.append(self.episode)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        if deadline==0:\n",
    "            self.failure+=1\n",
    "            print self.failure\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        if self.episode==10:\n",
    "            df1=pd.DataFrame(self.preserve,columns=['Time','Reward','Deadline','Episode'])\n",
    "            print self.preserve\n",
    "            print df1\n",
    "            df1.to_csv('report.csv')\n",
    "            return df1\n",
    "       \n",
    "        \n",
    "    \n",
    "def run():\n",
    "    \"\"\"Run the agent for a finite number of trials.\"\"\"\n",
    "    # Set up environment and agent\n",
    "    e = Environment()  # create environment (also adds some dummy traffic)\n",
    "    a = e.create_agent(LearningAgent)  # create agent\n",
    "    e.set_primary_agent(a, enforce_deadline=True)  # set agent to track\n",
    "    # Now simulate it\n",
    "    sim = Simulator(e, update_delay=0.1,display=True)  # reduce update_delay to speed up simulation\n",
    "    sim.run(n_trials=100)  # press Esc or close pygame window to quit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[[0, 2.0, 30, 1], [1, 1.5, 29, 1], [2, 3.5, 28, 1], [3, 3.0, 27, 1], [4, 3.0, 26, 1], [5, 5.0, 25, 1], [6, 5.0, 24, 1], [7, 5.0, 23, 1], [8, 4.5, 22, 1], [9, 4.0, 21, 1], [10, 6.0, 20, 1], [11, 8.0, 19, 1], [12, 7.5, 18, 1], [13, 9.5, 17, 1], [14, 8.5, 16, 1], [15, 8.0, 15, 1], [16, 10.0, 14, 1], [17, 12.0, 13, 1], [18, 14.0, 12, 1], [19, 14.0, 11, 1], [20, 13.5, 10, 1], [21, 13.5, 9, 1], [22, 13.5, 8, 1], [23, 15.5, 7, 1], [24, 17.5, 6, 1], [25, 19.5, 5, 1], [26, 18.5, 4, 1], [27, 17.5, 3, 1], [28, 16.5, 2, 1], [29, 16.0, 1, 1], [30, 18.0, 0, 1], [0, 2.0, 40, 2], [1, 4.0, 39, 2], [2, 3.0, 38, 2], [3, 3.0, 37, 2], [4, 5.0, 36, 2], [5, 14.5, 35, 2], [0, -1.0, 25, 3], [1, -2.0, 24, 3], [2, -3.0, 23, 3], [3, -1.0, 22, 3], [4, -2.0, 21, 3], [5, -2.0, 20, 3], [6, -2.5, 19, 3], [7, -3.0, 18, 3], [8, -1.0, 17, 3], [9, 1.0, 16, 3], [10, 0.5, 15, 3], [11, 2.5, 14, 3], [12, 2.0, 13, 3], [13, 4.0, 12, 3], [14, 6.0, 11, 3], [15, 8.0, 10, 3], [16, 10.0, 9, 3], [17, 12.0, 8, 3], [18, 11.5, 7, 3], [19, 13.5, 6, 3], [20, 13.5, 5, 3], [21, 12.5, 4, 3], [22, 14.5, 3, 3], [23, 16.5, 2, 3], [24, 15.5, 1, 3], [25, 14.5, 0, 3], [0, 2.0, 35, 4], [1, 2.0, 34, 4], [2, 1.5, 33, 4], [3, 3.5, 32, 4], [4, 3.0, 31, 4], [5, 5.0, 30, 4], [6, 7.0, 29, 4], [7, 7.0, 28, 4], [8, 7.0, 27, 4], [9, 6.0, 26, 4], [10, 18.0, 25, 4], [0, -0.5, 30, 5], [1, 1.5, 29, 5], [2, 3.5, 28, 5], [3, 3.0, 27, 5], [4, 2.5, 26, 5], [5, 4.5, 25, 5], [6, 6.5, 24, 5], [7, 6.0, 23, 5], [8, 8.0, 22, 5], [9, 10.0, 21, 5], [10, 12.0, 20, 5], [11, 11.0, 19, 5], [12, 10.0, 18, 5], [13, 9.5, 17, 5], [14, 8.5, 16, 5], [15, 8.5, 15, 5], [16, 10.5, 14, 5], [17, 9.5, 13, 5], [18, 8.5, 12, 5], [19, 8.5, 11, 5], [20, 20.5, 10, 5], [0, 2.0, 20, 6], [1, 4.0, 19, 6], [2, 3.5, 18, 6], [3, 5.5, 17, 6], [4, 7.5, 16, 6], [5, 9.5, 15, 6], [6, 11.5, 14, 6], [7, 23.5, 13, 6], [0, 2.0, 20, 7], [1, 2.0, 19, 7], [2, 1.0, 18, 7], [3, 0.0, 17, 7], [4, 2.0, 16, 7], [5, 2.0, 15, 7], [6, 2.0, 14, 7], [7, 2.0, 13, 7], [8, 4.0, 12, 7], [9, 4.0, 11, 7], [10, 3.0, 10, 7], [11, 2.5, 9, 7], [12, 2.0, 8, 7], [13, 4.0, 7, 7], [14, 6.0, 6, 7], [15, 18.0, 5, 7], [0, -0.5, 25, 8], [1, -1.5, 24, 8], [2, -2.5, 23, 8], [3, -3.5, 22, 8], [4, -3.5, 21, 8], [5, -1.5, 20, 8], [6, -2.5, 19, 8], [7, -2.5, 18, 8], [8, -2.5, 17, 8], [9, -3.5, 16, 8], [10, -1.5, 15, 8], [11, -2.5, 14, 8], [12, -0.5, 13, 8], [13, -0.5, 12, 8], [14, -1.5, 11, 8], [15, 10.5, 10, 8], [0, 2.0, 20, 9], [1, 1.0, 19, 9], [2, 0.5, 18, 9], [3, 0.0, 17, 9], [4, -0.5, 16, 9], [5, -1.5, 15, 9], [6, -2.5, 14, 9], [7, -3.5, 13, 9], [8, -4.5, 12, 9], [9, -5.0, 11, 9], [10, -5.0, 10, 9], [11, -3.0, 9, 9], [12, -1.0, 8, 9], [13, -2.0, 7, 9], [14, -3.0, 6, 9], [15, -4.0, 5, 9], [16, -2.0, 4, 9], [17, 0.0, 3, 9], [18, -1.0, 2, 9], [19, -2.0, 1, 9], [20, -2.0, 0, 9], [0, 2.0, 25, 10], [1, 4.0, 24, 10], [2, 6.0, 23, 10], [3, 8.0, 22, 10], [4, 7.5, 21, 10], [5, 9.5, 20, 10], [6, 11.5, 19, 10], [7, 13.5, 18, 10], [8, 12.5, 17, 10], [9, 12.5, 16, 10], [10, 12.0, 15, 10], [11, 14.0, 14, 10], [12, 16.0, 13, 10], [13, 18.0, 12, 10], [14, 17.5, 11, 10], [15, 17.0, 10, 10], [16, 19.0, 9, 10], [17, 18.0, 8, 10], [18, 20.0, 7, 10], [19, 22.0, 6, 10], [20, 21.0, 5, 10], [21, 20.0, 4, 10], [22, 19.0, 3, 10], [23, 19.0, 2, 10], [24, 19.0, 1, 10], [25, 18.5, 0, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=[[0, 2.0, 30, 1], [1, 1.5, 29, 1], [2, 3.5, 28, 1], [3, 3.0, 27, 1], [4, 3.0, 26, 1], [5, 5.0, 25, 1], [6, 5.0, 24, 1], [7, 5.0, 23, 1], [8, 4.5, 22, 1], [9, 4.0, 21, 1], [10, 6.0, 20, 1], [11, 8.0, 19, 1], [12, 7.5, 18, 1], [13, 9.5, 17, 1], [14, 8.5, 16, 1], [15, 8.0, 15, 1], [16, 10.0, 14, 1], [17, 12.0, 13, 1], [18, 14.0, 12, 1], [19, 14.0, 11, 1], [20, 13.5, 10, 1], [21, 13.5, 9, 1], [22, 13.5, 8, 1], [23, 15.5, 7, 1], [24, 17.5, 6, 1], [25, 19.5, 5, 1], [26, 18.5, 4, 1], [27, 17.5, 3, 1], [28, 16.5, 2, 1], [29, 16.0, 1, 1], [30, 18.0, 0, 1], [0, 2.0, 40, 2], [1, 4.0, 39, 2], [2, 3.0, 38, 2], [3, 3.0, 37, 2], [4, 5.0, 36, 2], [5, 14.5, 35, 2], [0, -1.0, 25, 3], [1, -2.0, 24, 3], [2, -3.0, 23, 3], [3, -1.0, 22, 3], [4, -2.0, 21, 3], [5, -2.0, 20, 3], [6, -2.5, 19, 3], [7, -3.0, 18, 3], [8, -1.0, 17, 3], [9, 1.0, 16, 3], [10, 0.5, 15, 3], [11, 2.5, 14, 3], [12, 2.0, 13, 3], [13, 4.0, 12, 3], [14, 6.0, 11, 3], [15, 8.0, 10, 3], [16, 10.0, 9, 3], [17, 12.0, 8, 3], [18, 11.5, 7, 3], [19, 13.5, 6, 3], [20, 13.5, 5, 3], [21, 12.5, 4, 3], [22, 14.5, 3, 3], [23, 16.5, 2, 3], [24, 15.5, 1, 3], [25, 14.5, 0, 3], [0, 2.0, 35, 4], [1, 2.0, 34, 4], [2, 1.5, 33, 4], [3, 3.5, 32, 4], [4, 3.0, 31, 4], [5, 5.0, 30, 4], [6, 7.0, 29, 4], [7, 7.0, 28, 4], [8, 7.0, 27, 4], [9, 6.0, 26, 4], [10, 18.0, 25, 4], [0, -0.5, 30, 5], [1, 1.5, 29, 5], [2, 3.5, 28, 5], [3, 3.0, 27, 5], [4, 2.5, 26, 5], [5, 4.5, 25, 5], [6, 6.5, 24, 5], [7, 6.0, 23, 5], [8, 8.0, 22, 5], [9, 10.0, 21, 5], [10, 12.0, 20, 5], [11, 11.0, 19, 5], [12, 10.0, 18, 5], [13, 9.5, 17, 5], [14, 8.5, 16, 5], [15, 8.5, 15, 5], [16, 10.5, 14, 5], [17, 9.5, 13, 5], [18, 8.5, 12, 5], [19, 8.5, 11, 5], [20, 20.5, 10, 5], [0, 2.0, 20, 6], [1, 4.0, 19, 6], [2, 3.5, 18, 6], [3, 5.5, 17, 6], [4, 7.5, 16, 6], [5, 9.5, 15, 6], [6, 11.5, 14, 6], [7, 23.5, 13, 6], [0, 2.0, 20, 7], [1, 2.0, 19, 7], [2, 1.0, 18, 7], [3, 0.0, 17, 7], [4, 2.0, 16, 7], [5, 2.0, 15, 7], [6, 2.0, 14, 7], [7, 2.0, 13, 7], [8, 4.0, 12, 7], [9, 4.0, 11, 7], [10, 3.0, 10, 7], [11, 2.5, 9, 7], [12, 2.0, 8, 7], [13, 4.0, 7, 7], [14, 6.0, 6, 7], [15, 18.0, 5, 7], [0, -0.5, 25, 8], [1, -1.5, 24, 8], [2, -2.5, 23, 8], [3, -3.5, 22, 8], [4, -3.5, 21, 8], [5, -1.5, 20, 8], [6, -2.5, 19, 8], [7, -2.5, 18, 8], [8, -2.5, 17, 8], [9, -3.5, 16, 8], [10, -1.5, 15, 8], [11, -2.5, 14, 8], [12, -0.5, 13, 8], [13, -0.5, 12, 8], [14, -1.5, 11, 8], [15, 10.5, 10, 8], [0, 2.0, 20, 9], [1, 1.0, 19, 9], [2, 0.5, 18, 9], [3, 0.0, 17, 9], [4, -0.5, 16, 9], [5, -1.5, 15, 9], [6, -2.5, 14, 9], [7, -3.5, 13, 9], [8, -4.5, 12, 9], [9, -5.0, 11, 9], [10, -5.0, 10, 9], [11, -3.0, 9, 9], [12, -1.0, 8, 9], [13, -2.0, 7, 9], [14, -3.0, 6, 9], [15, -4.0, 5, 9], [16, -2.0, 4, 9], [17, 0.0, 3, 9], [18, -1.0, 2, 9], [19, -2.0, 1, 9], [20, -2.0, 0, 9], [0, 2.0, 25, 10], [1, 4.0, 24, 10], [2, 6.0, 23, 10], [3, 8.0, 22, 10], [4, 7.5, 21, 10], [5, 9.5, 20, 10], [6, 11.5, 19, 10], [7, 13.5, 18, 10], [8, 12.5, 17, 10], [9, 12.5, 16, 10], [10, 12.0, 15, 10], [11, 14.0, 14, 10], [12, 16.0, 13, 10], [13, 18.0, 12, 10], [14, 17.5, 11, 10], [15, 17.0, 10, 10], [16, 19.0, 9, 10], [17, 18.0, 8, 10], [18, 20.0, 7, 10], [19, 22.0, 6, 10], [20, 21.0, 5, 10], [21, 20.0, 4, 10], [22, 19.0, 3, 10], [23, 19.0, 2, 10], [24, 19.0, 1, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(b,columns=['Time','Reward','Deadline','Episode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e51f5dd68a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'deadline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-6906b1e4a953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mLearningAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeadline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'deadline'"
     ]
    }
   ],
   "source": [
    "print LearningAgent.update.deadline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"Deadline\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>40</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>40</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>561</td>\n",
       "      <td>20</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>649</td>\n",
       "      <td>20</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>757</td>\n",
       "      <td>20</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923</td>\n",
       "      <td>40</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>977</td>\n",
       "      <td>25</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1304</td>\n",
       "      <td>20</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>1658</td>\n",
       "      <td>30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Time  Reward  Deadline  Episode\n",
       "49            49    20    17.0         0        2\n",
       "308          308    40    11.5         0       17\n",
       "467          467    40    19.5         0       24\n",
       "561          561    20    15.5         0       31\n",
       "649          649    20     3.5         0       37\n",
       "757          757    20    11.0         0       43\n",
       "923          923    40    30.0         0       52\n",
       "977          977    25     4.5         0       56\n",
       "1231        1231    30    19.0         0       70\n",
       "1304        1304    20    11.5         0       74\n",
       "1658        1658    30    21.0         0       97"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Deadline\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num=df[df[\"Time\"]==0][\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_totalreward=df.ix[num-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_total_reward=df_totalreward.drop(df_totalreward.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>22.5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>20.5</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>13</td>\n",
       "      <td>26.5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>22</td>\n",
       "      <td>18.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "      <td>23.5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>13</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>15</td>\n",
       "      <td>21.5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>6</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>26.5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>19</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>20</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>267</td>\n",
       "      <td>24</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>40</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>20</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>7</td>\n",
       "      <td>23.5</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>33</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>388</td>\n",
       "      <td>16</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>18</td>\n",
       "      <td>20.5</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>426</td>\n",
       "      <td>18</td>\n",
       "      <td>30.5</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>40</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>17</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>518</td>\n",
       "      <td>13</td>\n",
       "      <td>20.5</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>13</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1247</td>\n",
       "      <td>15</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1269</td>\n",
       "      <td>21</td>\n",
       "      <td>29.5</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>1283</td>\n",
       "      <td>13</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1304</td>\n",
       "      <td>20</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1311</td>\n",
       "      <td>6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>1316</td>\n",
       "      <td>4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>36</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1331</td>\n",
       "      <td>14</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1337</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1355</td>\n",
       "      <td>17</td>\n",
       "      <td>18.5</td>\n",
       "      <td>8</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1369</td>\n",
       "      <td>13</td>\n",
       "      <td>23.5</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>1383</td>\n",
       "      <td>13</td>\n",
       "      <td>21.5</td>\n",
       "      <td>32</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>1401</td>\n",
       "      <td>17</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1433</td>\n",
       "      <td>31</td>\n",
       "      <td>37.5</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1438</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1451</td>\n",
       "      <td>12</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1461</td>\n",
       "      <td>9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>1480</td>\n",
       "      <td>18</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1490</td>\n",
       "      <td>9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>16</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1504</td>\n",
       "      <td>13</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>1522</td>\n",
       "      <td>17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>1538</td>\n",
       "      <td>15</td>\n",
       "      <td>19.5</td>\n",
       "      <td>15</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1560</td>\n",
       "      <td>21</td>\n",
       "      <td>18.5</td>\n",
       "      <td>24</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>1571</td>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1590</td>\n",
       "      <td>18</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>1608</td>\n",
       "      <td>17</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>1627</td>\n",
       "      <td>18</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>1658</td>\n",
       "      <td>30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1669</td>\n",
       "      <td>10</td>\n",
       "      <td>14.5</td>\n",
       "      <td>25</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1697</td>\n",
       "      <td>27</td>\n",
       "      <td>38.5</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Time  Reward  Deadline  Episode\n",
       "28            28    28    22.5         7        1\n",
       "49            49    20    17.0         0        2\n",
       "59            59     9    20.5        26        3\n",
       "73            73    13    26.5        12        4\n",
       "83            83     9    17.5        21        5\n",
       "106          106    22    18.5         3        6\n",
       "127          127    20    23.5         5        7\n",
       "136          136     8    17.0        17        8\n",
       "150          150    13    19.0         7        9\n",
       "166          166    15    21.0        15       10\n",
       "182          182    15    21.5        10       11\n",
       "189          189     6    14.5        14       12\n",
       "201          201    11    26.5        19       13\n",
       "221          221    19    20.0         6       14\n",
       "242          242    20    25.0        25       15\n",
       "267          267    24    19.0        16       16\n",
       "308          308    40    11.5         0       17\n",
       "329          329    20    22.0         5       18\n",
       "337          337     7    23.5        13       19\n",
       "371          371    33    35.0         2       20\n",
       "388          388    16    26.0         4       21\n",
       "407          407    18    20.5        37       22\n",
       "426          426    18    30.5        12       23\n",
       "467          467    40    19.5         0       24\n",
       "485          485    17    25.0        13       25\n",
       "498          498    12    16.0        13       26\n",
       "504          504     5    18.0        15       27\n",
       "518          518    13    20.5        27       28\n",
       "532          532    13    24.0        12       29\n",
       "540          540     7    15.0        13       30\n",
       "...          ...   ...     ...       ...      ...\n",
       "1231        1231    30    19.0         0       70\n",
       "1247        1247    15    30.0        20       71\n",
       "1269        1269    21    29.5         9       72\n",
       "1283        1283    13    22.0         7       73\n",
       "1304        1304    20    11.5         0       74\n",
       "1311        1311     6    19.5        24       75\n",
       "1316        1316     4     9.5        36       76\n",
       "1331        1331    14    25.5         6       77\n",
       "1337        1337     5    18.0        15       78\n",
       "1355        1355    17    18.5         8       79\n",
       "1369        1369    13    23.5        32       80\n",
       "1383        1383    13    21.5        32       81\n",
       "1401        1401    17    26.0        13       82\n",
       "1433        1433    31    37.5        24       83\n",
       "1438        1438     4    18.0        16       84\n",
       "1451        1451    12    22.0        13       85\n",
       "1461        1461     9    19.0        21       86\n",
       "1480        1480    18    24.0        22       87\n",
       "1490        1490     9    19.5        16       88\n",
       "1504        1504    13    21.5        22       89\n",
       "1522        1522    17    28.0        18       90\n",
       "1538        1538    15    19.5        15       91\n",
       "1560        1560    21    18.5        24       92\n",
       "1571        1571    10    13.0        10       93\n",
       "1590        1590    18    21.5         2       94\n",
       "1608        1608    17    27.0        18       95\n",
       "1627        1627    18    15.5         2       96\n",
       "1658        1658    30    21.0         0       97\n",
       "1669        1669    10    14.5        25       98\n",
       "1697        1697    27    38.5        13       99\n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryosuke/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10aa382d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKIpSggqDoiiKUoIKg6IoilLC/wfl/GVuyX3/pQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a93f590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_total_reward[\"Episode\"],df_total_reward[\"Reward\"])\n",
    "plt.xlabel(\"No.Episode\")\n",
    "plt.ylabel(\"Total Reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
